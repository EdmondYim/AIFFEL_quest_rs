{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe31ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import sentencepiece as spm\n",
    "\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "# import urllib.request\n",
    "# import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c9c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.position = position\n",
    "\n",
    "        self.pos_encoding = self._build_pos_encoding(position, d_model)\n",
    "\n",
    "    def _get_angles(self, position, i, d_model):\n",
    "        return 1.0 / (10000.0 ** ((2.0 * (i // 2)) / d_model)) * position\n",
    "\n",
    "    def _build_pos_encoding(self, position, d_model):\n",
    "        pos = torch.arange(position, dtype=torch.float32).unsqueeze(1)\n",
    "        i = torch.arange(d_model, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        angle_rads = self._get_angles(pos, i, d_model)\n",
    "        sines = torch.sin(angle_rads[:, 0::2])\n",
    "        cosines = torch.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = torch.zeros(position, d_model)\n",
    "        pos_encoding[:, 0::2] = sines\n",
    "        pos_encoding[:, 1::2] = cosines\n",
    "\n",
    "        pos_encoding = pos_encoding.unsqueeze(0)  # shape: [1, position, d_model]\n",
    "        return pos_encoding\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pos_encoding[:, :x.size(1), :].to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf3ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "\n",
    "    # 1) Q와 K의 내적을 통해 score(유사도) 계산\n",
    "    # key.transpose(-1, -2): (batch_size, heads, depth, seq_len)\n",
    "    # matmul 결과 shape: (batch_size, heads, seq_len, seq_len)\n",
    "    matmul_qk = torch.matmul(query, key.transpose(-1, -2))\n",
    "\n",
    "    # 2) depth에 따라 정규화\n",
    "    depth = key.size(-1)  # depth = d_model / heads\n",
    "    logits = matmul_qk / math.sqrt(depth)\n",
    "\n",
    "    # 3) 마스크가 주어졌다면 -1e9(아주 작은 값)를 더해 소프트맥스에서 제외시키도록 함\n",
    "    if mask is not None:\n",
    "        # 텐서플로우: logits += (mask * -1e9)\n",
    "        # 파이토치 동일 적용\n",
    "        logits = logits + (mask * -1e9)\n",
    "\n",
    "    # 4) 소프트맥스 계산해 attention weights 생성\n",
    "    attention_weights = F.softmax(logits, dim=-1)\n",
    "\n",
    "    # 5) attention weights와 value의 내적\n",
    "    output = torch.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef3a883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # d_model은 num_heads로 나누어떨어져야 함\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        # 파이토치에서 Dense는 nn.Linear로 대응\n",
    "        self.query_dense = nn.Linear(d_model, d_model)\n",
    "        self.key_dense = nn.Linear(d_model, d_model)\n",
    "        self.value_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.out_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, d_model)\n",
    "        => (batch_size, num_heads, seq_len, depth) 형태로 변환\n",
    "        \"\"\"\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
    "        x = x.permute(0, 2, 1, 3)  # (batch_size, num_heads, seq_len, depth)\n",
    "        return x\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "        query, key, value: (batch_size, seq_len, d_model)\n",
    "        mask: (batch_size, 1, seq_len, seq_len) 등으로 broadcast 가능하도록 구성\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # Q, K, V에 각각 Linear 적용\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # Head 분할\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, depth) -> (batch_size, seq_len, num_heads, depth)\n",
    "        scaled_attention = scaled_attention.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "        # 다시 (batch_size, seq_len, d_model)로 합치기\n",
    "        concat_attention = scaled_attention.view(batch_size, -1, self.d_model)\n",
    "\n",
    "        # 최종 Dense\n",
    "        output = self.out_dense(concat_attention)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0703229",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)  # 이전에 구현한 MHA\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 피드포워드 부분 (Dense -> ReLU -> Dense)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, d_model)\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # (1) 멀티 헤드 어텐션 (셀프 어텐션)\n",
    "        attn_output = self.mha(x, x, x, mask)  # (batch_size, seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.norm1(x + attn_output)     # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # (2) 피드포워드 신경망\n",
    "        ffn_output = self.ffn(out1)            # (batch_size, seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.norm2(out1 + ffn_output)   # 잔차 연결 + LayerNorm\n",
    "\n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a33ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 ff_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # (1) 임베딩 레이어\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩\n",
    "        self.pos_encoding = PositionalEncoding(position=vocab_size, d_model=d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # (3) EncoderLayer 쌓기\n",
    "        self.enc_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # (1) 임베딩 & sqrt(d_model)로 스케일링\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩 적용 + 드롭아웃\n",
    "        x = self.pos_encoding(x)  # shape: (batch_size, seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # (3) num_layers만큼 쌓아올린 EncoderLayer 통과\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83aadab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        # 첫 번째 서브 레이어 (디코더 내부 셀프 어텐션)\n",
    "        self.self_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 두 번째 서브 레이어 (인코더-디코더 어텐션)\n",
    "        self.encdec_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 세 번째 서브 레이어 (피드포워드 네트워크)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),  # Dense(units=ff_dim)\n",
    "            nn.ReLU(),                   # activation='relu'\n",
    "            nn.Linear(ff_dim, d_model)   # Dense(units=d_model)\n",
    "        )\n",
    "        self.norm3 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 드롭아웃\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_outputs, look_ahead_mask=None, padding_mask=None):\n",
    "        # 1) 셀프 어텐션 (디코더 내부)\n",
    "        self_attn_out = self.self_mha(x, x, x, mask=look_ahead_mask)\n",
    "        self_attn_out = self.dropout1(self_attn_out)\n",
    "        out1 = self.norm1(x + self_attn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # 2) 인코더-디코더 어텐션\n",
    "        encdec_attn_out = self.encdec_mha(out1, enc_outputs, enc_outputs, mask=padding_mask)\n",
    "        encdec_attn_out = self.dropout2(encdec_attn_out)\n",
    "        out2 = self.norm2(out1 + encdec_attn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # 3) 피드포워드 (Dense -> ReLU -> Dense)\n",
    "        ffn_out = self.ffn(out2)\n",
    "        ffn_out = self.dropout3(ffn_out)\n",
    "        out3 = self.norm3(out2 + ffn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf3e9d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 ff_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # (1) 임베딩 레이어\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩\n",
    "        # 실제 학습 시에는 최대 시퀀스 길이에 맞추어 쓰기도 함\n",
    "        self.pos_encoding = PositionalEncoding(position=vocab_size, d_model=d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # (3) DecoderLayer 쌓기\n",
    "        self.dec_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, enc_outputs, look_ahead_mask=None, padding_mask=None):\n",
    "        # (1) 임베딩 + sqrt(d_model)로 스케일링\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩 + 드롭아웃\n",
    "        x = self.pos_encoding(x)    # (batch_size, tgt_seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # (3) num_layers만큼 쌓인 DecoderLayer 통과\n",
    "        for layer in self.dec_layers:\n",
    "            x = layer(x, enc_outputs, look_ahead_mask, padding_mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d32b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 폴더 경로\n",
    "path = 'ChatbotData.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f513a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # 1. 유니코드 정규화\n",
    "    sentence = unicodedata.normalize(\"NFC\", sentence)\n",
    "\n",
    "    # 2. 문장부호 앞뒤에 공백 삽입\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
    "\n",
    "    # 3. 허용 문자만 유지 (한글, 자모, 영문, 숫자, 공백, 주요 문장부호)\n",
    "    sentence = re.sub(r\"[^가-힣ㄱ-ㅎㅏ-ㅣA-Za-z0-9?.!,~… ]\", \" \", sentence)\n",
    "\n",
    "    # 4. 감정 표현 반복 상한 (4개 이상 → 2개)\n",
    "    sentence = re.sub(r'(ㅋ)\\1{3,}', r'\\1\\1', sentence)\n",
    "    sentence = re.sub(r'(ㅎ)\\1{3,}', r'\\1\\1', sentence)\n",
    "    sentence = re.sub(r'(ㅠ)\\1{3,}', r'\\1\\1', sentence)\n",
    "    sentence = re.sub(r'(ㅜ)\\1{3,}', r'\\1\\1', sentence)\n",
    "\n",
    "    # 5. 공백 정리\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence).strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ece1f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chatbot_csv(path,preprocess_sentence):\n",
    "    \"\"\"\n",
    "    반환: [(Q_clean, A_clean, label), ...]\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    qs = df[\"Q\"].astype(str).map(preprocess_sentence)\n",
    "    as_ = df[\"A\"].astype(str).map(preprocess_sentence)\n",
    "    labels = df[\"label\"].astype(int)\n",
    "    return list(zip(qs, as_, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fdd55dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    # x == 0 위치를 찾아 float형 1로 변환\n",
    "    mask = (x == 0).float()\n",
    "    # (batch_size, seq_len) -> (batch_size, 1, 1, seq_len)\n",
    "    mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "108ff8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = x.size(1)\n",
    "\n",
    "    # (seq_len, seq_len) 크기의 하삼각 행렬(tril) 생성 후 1에서 빼서\n",
    "    # 상삼각이 1, 하삼각(자기 자신 포함)이 0이 되도록 설정\n",
    "    # => 미래 토큰(자신 인덱스보다 큰 위치) 마스킹\n",
    "    look_ahead_mask = 1 - torch.tril(torch.ones((seq_len, seq_len)))\n",
    "\n",
    "    # 패딩 마스크 생성 (shape: (batch_size, 1, 1, seq_len))\n",
    "    padding_mask = create_padding_mask(x)\n",
    "\n",
    "    # look_ahead_mask: (seq_len, seq_len) -> (1, seq_len, seq_len)\n",
    "    look_ahead_mask = look_ahead_mask.unsqueeze(0)\n",
    "    # -> (1, seq_len, seq_len) -> (1, 1, seq_len, seq_len)\n",
    "    look_ahead_mask = look_ahead_mask.unsqueeze(1)\n",
    "    look_ahead_mask = look_ahead_mask.to(x.device)\n",
    "\n",
    "    # look-ahead 마스크와 패딩 마스크를 합성 (둘 중 하나라도 1이면 마스킹)\n",
    "    # 최종 shape은 브로드캐스팅으로 (batch_size, 1, seq_len, seq_len)\n",
    "    combined_mask = torch.max(look_ahead_mask, padding_mask)\n",
    "    return combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487105d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ clean_corpus.txt 생성 완료\n"
     ]
    }
   ],
   "source": [
    "data = load_chatbot_csv(path, preprocess_sentence)\n",
    "\n",
    "with open(\"clean_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for q, a, label in data:\n",
    "        if q and a:\n",
    "            f.write(f\"{label}\\t{q}\\t{a}\\n\")\n",
    "\n",
    "print(\"clean_corpus.txt 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76af4f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train(\n",
    "    input='clean_corpus.txt',\n",
    "    model_prefix=\"chatbot_spm\",\n",
    "    vocab_size=16000,\n",
    "    character_coverage=0.9995,\n",
    "    model_type=\"bpe\",  # 한국어면 unigram도 가능\n",
    "    max_sentence_length=999999,\n",
    "\n",
    "    # 특수 토큰 ID 설정\n",
    "    pad_id=0,   # <pad>\n",
    "    unk_id=1,   # <unk>\n",
    "    bos_id=2,   # <s>\n",
    "    eos_id=3,   # </s>\n",
    "\n",
    "    # label을 포함한 사용자 정의 토큰\n",
    "    user_defined_symbols=[\n",
    "        \"<label_0>\", \"<label_1>\", \"<label_2>\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc77c764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"chatbot_spm.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c1a511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5 6\n"
     ]
    }
   ],
   "source": [
    "print(sp.piece_to_id(\"<label_0>\"), sp.piece_to_id(\"<label_1>\"), sp.piece_to_id(\"<label_2>\"))\n",
    "\n",
    "# label 0,1,2 가 토큰 4,5,6에 매핑됨을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee975af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self, data, sp, max_length=40):\n",
    "        self.sp = sp\n",
    "        self.max_length = max_length\n",
    "        self.data = []\n",
    "\n",
    "        # spm 모델에 정의된 토큰 ID를 동적으로 가져오기\n",
    "        self.label_map = {\n",
    "            0: self.sp.piece_to_id('<label_0>'),\n",
    "            1: self.sp.piece_to_id('<label_1>'),\n",
    "            2: self.sp.piece_to_id('<label_2>')\n",
    "        }\n",
    "\n",
    "        \n",
    "        for q, a, label in data:\n",
    "            bos_id = self.sp.bos_id()\n",
    "            eos_id = self.sp.eos_id()\n",
    "            label_token = self.label_map[label]\n",
    "\n",
    "            q_ids = self.sp.encode_as_ids(q)\n",
    "            a_ids = self.sp.encode_as_ids(a)\n",
    "\n",
    "            q_tokens = [label_token] + [bos_id] + q_ids + [eos_id]\n",
    "            a_tokens = [bos_id] + a_ids + [eos_id]\n",
    "\n",
    "            if len(q_tokens) > self.max_length or len(a_tokens) > self.max_length:\n",
    "                continue\n",
    "\n",
    "            q_tokens += [self.sp.pad_id()] * (self.max_length - len(q_tokens))\n",
    "            a_tokens += [self.sp.pad_id()] * (self.max_length - len(a_tokens))\n",
    "\n",
    "            dec_input = a_tokens[:-1]\n",
    "            target = a_tokens[1:]\n",
    "\n",
    "            self.data.append({\n",
    "                \"enc_input\": q_tokens,\n",
    "                \"dec_input\": dec_input,\n",
    "                \"target\": target\n",
    "            })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        enc_input = torch.tensor(sample[\"enc_input\"], dtype=torch.long)\n",
    "        dec_input = torch.tensor(sample[\"dec_input\"], dtype=torch.long)\n",
    "        target = torch.tensor(sample[\"target\"], dtype=torch.long)\n",
    "        return enc_input, dec_input, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6146841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_chatbot_csv(path, preprocess_sentence)\n",
    "dataset = ChatbotDataset(data, sp, max_length=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7db03529",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38786e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40])\n",
      "torch.Size([32, 39])\n",
      "torch.Size([32, 39])\n"
     ]
    }
   ],
   "source": [
    "for encoder_input, decoder_input, decoder_label in dataloader:\n",
    "    print(encoder_input.size())\n",
    "    print(decoder_input.size())\n",
    "    print(decoder_label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f63da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,      # 인코더/디코더 층 수\n",
    "                 units,           # feed-forward 네트워크의 중간 차원(ff_dim)\n",
    "                 d_model,         # 임베딩 및 내부 표현 차원\n",
    "                 num_heads,       # 멀티헤드 어텐션의 헤드 수\n",
    "                 dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        # 인코더\n",
    "        self.encoder = Encoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # 디코더\n",
    "        self.decoder = Decoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # 최종 출력층: (d_model) -> (vocab_size)\n",
    "        self.final_linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        # 참고: 텐서플로우 코드의 `name=\"transformer\"`는 파이토치에선 보통 사용 안 함\n",
    "\n",
    "    def forward(self, inputs, dec_inputs):\n",
    "        # 1) 인코더 패딩 마스크 생성\n",
    "        enc_padding_mask = create_padding_mask(inputs)     # shape (batch_size, 1, 1, src_seq_len)\n",
    "\n",
    "        # 2) 디코더 look-ahead + 패딩 마스크\n",
    "        look_ahead_mask = create_look_ahead_mask(dec_inputs)  # shape (batch_size, 1, tgt_seq_len, tgt_seq_len)\n",
    "\n",
    "        # 3) 디코더에서 인코더 출력 쪽을 마스킹할 때 쓸 패딩 마스크\n",
    "        dec_padding_mask = create_padding_mask(inputs)        # shape (batch_size, 1, 1, src_seq_len)\n",
    "\n",
    "        # 4) 인코더 수행\n",
    "        enc_outputs = self.encoder(\n",
    "            x=inputs,\n",
    "            mask=enc_padding_mask\n",
    "        )  # shape: (batch_size, src_seq_len, d_model)\n",
    "\n",
    "        # 5) 디코더 수행\n",
    "        dec_outputs = self.decoder(\n",
    "            x=dec_inputs,           # (batch_size, tgt_seq_len)\n",
    "            enc_outputs=enc_outputs,# (batch_size, src_seq_len, d_model)\n",
    "            look_ahead_mask=look_ahead_mask,\n",
    "            padding_mask=dec_padding_mask\n",
    "        )  # shape: (batch_size, tgt_seq_len, d_model)\n",
    "\n",
    "        # 6) 최종 Dense (vocab_size)\n",
    "        logits = self.final_linear(dec_outputs)  # (batch_size, tgt_seq_len, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "507aaaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(8000, 256)\n",
      "    (pos_encoding): PositionalEncoding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (enc_layers): ModuleList(\n",
      "      (0-1): 2 x EncoderLayer(\n",
      "        (mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (key_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (value_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        )\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(8000, 256)\n",
      "    (pos_encoding): PositionalEncoding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (dec_layers): ModuleList(\n",
      "      (0-1): 2 x DecoderLayer(\n",
      "        (self_mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (key_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (value_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (encdec_mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (key_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (value_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        )\n",
      "        (norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_linear): Linear(in_features=256, out_features=8000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 예: 하이퍼파라미터 설정\n",
    "NUM_LAYERS = 2     # 인코더/디코더 층 수\n",
    "D_MODEL = 256      # 임베딩 및 내부 표현 차원\n",
    "NUM_HEADS = 8      # 멀티헤드 어텐션에서의 헤드 수\n",
    "UNITS = 512        # 피드포워드 신경망의 은닉 차원\n",
    "DROPOUT = 0.1      # 드롭아웃 비율\n",
    "VOCAB_SIZE = 16000 # 단어 집합 크기(예시)\n",
    "\n",
    "# 모델 생성\n",
    "model = Transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af03d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(ignore_index=sp.pad_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4eb312cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_lambda(d_model, warmup_steps=4000):\n",
    "    d_model = float(d_model)\n",
    "    def lr_lambda(step):\n",
    "        # step은 0부터 시작하므로 +1로 보정\n",
    "        step = step + 1\n",
    "        return (d_model ** -0.5) * min(step ** -0.5, step * (warmup_steps ** -1.5))\n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57736254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "d_model = 512\n",
    "warmup_steps = 4000\n",
    "total_steps = 200000  # 총 학습 스텝\n",
    "\n",
    "# 학습률 스케줄 시각화\n",
    "steps = np.arange(1, total_steps + 1)\n",
    "learning_rates = [get_lr_lambda(d_model, warmup_steps)(step) for step in steps]\n",
    "\n",
    "# 그래프 출력\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, learning_rates, label=\"Learning Rate\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Transformer Learning Rate Schedule\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3201c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer 정의\n",
    "optimizer = optim.AdamW(model.parameters(), betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "# Scheduler 정의\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=get_lr_lambda(D_MODEL, warmup_steps=4000))\n",
    "\n",
    "def accuracy_function(y_pred, y_true, pad_id=0):\n",
    "    \"\"\"\n",
    "    y_pred: (batch_size, seq_len, vocab_size)\n",
    "    y_true: (batch_size, seq_len)\n",
    "    \"\"\"\n",
    "    preds = y_pred.argmax(dim=-1)  # (batch_size, seq_len)\n",
    "    mask = (y_true != pad_id)\n",
    "    correct = (preds == y_true) & mask\n",
    "    acc = correct.float().sum() / mask.float().sum()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "deb05173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68d90fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, batch, optimizer, loss_function, device):\n",
    "    model.train()\n",
    "    enc_input, dec_input, target = [x.to(device) for x in batch]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 모델 포워드 패스\n",
    "    logits = model(enc_input, dec_input)  # (batch_size, seq_len, vocab_size)\n",
    "\n",
    "    # Loss 계산 (패딩 토큰 무시)\n",
    "    loss = loss_function(logits.permute(0, 2, 1), target)  # (batch_size, vocab_size, seq_len) 필요\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), accuracy_function(logits, target, pad_id=sp.pad_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69892077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_function, scheduler, num_epochs, device):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss, total_acc = 0, 0\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            loss, acc = train_step(model, batch, optimizer, loss_function, device)\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "\n",
    "            # 일정 스텝마다 로그 출력\n",
    "            if step % 100 == 0:\n",
    "                print(f\"[Epoch {epoch+1}, Step {step}] Loss: {loss:.4f}, Acc: {acc:.4f}\")\n",
    "\n",
    "            # 학습률 스케줄러 업데이트\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_acc = total_acc / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1} Completed - Avg Loss: {avg_loss:.4f}, Avg Acc: {avg_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "512c36bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Step 0] Loss: 9.2479, Acc: 0.0000\n",
      "[Epoch 1, Step 100] Loss: 9.2038, Acc: 0.0023\n",
      "[Epoch 1, Step 200] Loss: 9.1414, Acc: 0.0023\n",
      "[Epoch 1, Step 300] Loss: 9.2066, Acc: 0.0000\n",
      "[Epoch 1, Step 400] Loss: 9.1567, Acc: 0.0000\n",
      "[Epoch 1, Step 500] Loss: 9.1312, Acc: 0.0048\n",
      "[Epoch 1, Step 600] Loss: 9.1771, Acc: 0.0000\n",
      "[Epoch 1, Step 700] Loss: 9.1304, Acc: 0.0059\n",
      "[Epoch 1, Step 800] Loss: 9.1565, Acc: 0.0024\n",
      "[Epoch 1, Step 900] Loss: 9.1052, Acc: 0.0000\n",
      "[Epoch 1, Step 1000] Loss: 9.1177, Acc: 0.0000\n",
      "[Epoch 1, Step 1100] Loss: 9.1109, Acc: 0.0000\n",
      "[Epoch 1, Step 1200] Loss: 9.0612, Acc: 0.0024\n",
      "[Epoch 1, Step 1300] Loss: 8.9842, Acc: 0.0024\n",
      "Epoch 1 Completed - Avg Loss: 9.1368, Avg Acc: 0.0014\n",
      "[Epoch 2, Step 0] Loss: 8.9840, Acc: 0.0043\n",
      "[Epoch 2, Step 100] Loss: 8.9841, Acc: 0.0052\n",
      "[Epoch 2, Step 200] Loss: 8.9120, Acc: 0.0132\n",
      "[Epoch 2, Step 300] Loss: 8.9040, Acc: 0.0081\n",
      "[Epoch 2, Step 400] Loss: 8.8964, Acc: 0.0051\n",
      "[Epoch 2, Step 500] Loss: 8.7298, Acc: 0.0125\n",
      "[Epoch 2, Step 600] Loss: 8.6872, Acc: 0.0166\n",
      "[Epoch 2, Step 700] Loss: 8.7797, Acc: 0.0091\n",
      "[Epoch 2, Step 800] Loss: 8.6551, Acc: 0.0256\n",
      "[Epoch 2, Step 900] Loss: 8.6237, Acc: 0.0242\n",
      "[Epoch 2, Step 1000] Loss: 8.5532, Acc: 0.0564\n",
      "[Epoch 2, Step 1100] Loss: 8.4895, Acc: 0.0732\n",
      "[Epoch 2, Step 1200] Loss: 8.3905, Acc: 0.0899\n",
      "[Epoch 2, Step 1300] Loss: 8.2290, Acc: 0.1386\n",
      "Epoch 2 Completed - Avg Loss: 8.7269, Avg Acc: 0.0328\n",
      "[Epoch 3, Step 0] Loss: 8.2444, Acc: 0.1073\n",
      "[Epoch 3, Step 100] Loss: 8.2641, Acc: 0.1181\n",
      "[Epoch 3, Step 200] Loss: 8.2954, Acc: 0.1106\n",
      "[Epoch 3, Step 300] Loss: 8.2244, Acc: 0.1141\n",
      "[Epoch 3, Step 400] Loss: 8.1081, Acc: 0.1183\n",
      "[Epoch 3, Step 500] Loss: 8.0147, Acc: 0.1289\n",
      "[Epoch 3, Step 600] Loss: 7.9101, Acc: 0.1411\n",
      "[Epoch 3, Step 700] Loss: 8.0298, Acc: 0.1096\n",
      "[Epoch 3, Step 800] Loss: 7.9775, Acc: 0.0920\n",
      "[Epoch 3, Step 900] Loss: 7.9573, Acc: 0.1040\n",
      "[Epoch 3, Step 1000] Loss: 7.6119, Acc: 0.1205\n",
      "[Epoch 3, Step 1100] Loss: 7.8213, Acc: 0.0947\n",
      "[Epoch 3, Step 1200] Loss: 7.6169, Acc: 0.0970\n",
      "[Epoch 3, Step 1300] Loss: 7.5970, Acc: 0.1080\n",
      "Epoch 3 Completed - Avg Loss: 7.9061, Avg Acc: 0.1191\n",
      "[Epoch 4, Step 0] Loss: 7.4598, Acc: 0.1073\n",
      "[Epoch 4, Step 100] Loss: 7.6023, Acc: 0.1192\n",
      "[Epoch 4, Step 200] Loss: 7.3211, Acc: 0.1341\n",
      "[Epoch 4, Step 300] Loss: 7.3911, Acc: 0.1128\n",
      "[Epoch 4, Step 400] Loss: 7.4113, Acc: 0.1169\n",
      "[Epoch 4, Step 500] Loss: 7.3365, Acc: 0.1261\n",
      "[Epoch 4, Step 600] Loss: 7.1265, Acc: 0.1452\n",
      "[Epoch 4, Step 700] Loss: 7.3222, Acc: 0.1209\n",
      "[Epoch 4, Step 800] Loss: 7.2769, Acc: 0.1233\n",
      "[Epoch 4, Step 900] Loss: 7.2409, Acc: 0.1453\n",
      "[Epoch 4, Step 1000] Loss: 7.3401, Acc: 0.1395\n",
      "[Epoch 4, Step 1100] Loss: 7.2182, Acc: 0.1393\n",
      "[Epoch 4, Step 1200] Loss: 7.2242, Acc: 0.1173\n",
      "[Epoch 4, Step 1300] Loss: 6.8847, Acc: 0.1722\n",
      "Epoch 4 Completed - Avg Loss: 7.2776, Avg Acc: 0.1331\n",
      "[Epoch 5, Step 0] Loss: 6.8758, Acc: 0.1597\n",
      "[Epoch 5, Step 100] Loss: 6.8420, Acc: 0.2030\n",
      "[Epoch 5, Step 200] Loss: 7.0825, Acc: 0.1469\n",
      "[Epoch 5, Step 300] Loss: 6.9718, Acc: 0.1556\n",
      "[Epoch 5, Step 400] Loss: 7.0856, Acc: 0.1400\n",
      "[Epoch 5, Step 500] Loss: 6.8978, Acc: 0.1420\n",
      "[Epoch 5, Step 600] Loss: 7.0141, Acc: 0.1422\n",
      "[Epoch 5, Step 700] Loss: 6.9886, Acc: 0.1542\n",
      "[Epoch 5, Step 800] Loss: 6.7514, Acc: 0.1823\n",
      "[Epoch 5, Step 900] Loss: 6.8876, Acc: 0.1601\n",
      "[Epoch 5, Step 1000] Loss: 6.8926, Acc: 0.1875\n",
      "[Epoch 5, Step 1100] Loss: 6.9940, Acc: 0.1207\n",
      "[Epoch 5, Step 1200] Loss: 6.6028, Acc: 0.1890\n",
      "[Epoch 5, Step 1300] Loss: 6.8205, Acc: 0.1603\n",
      "Epoch 5 Completed - Avg Loss: 6.9592, Avg Acc: 0.1575\n",
      "[Epoch 6, Step 0] Loss: 6.7920, Acc: 0.1514\n",
      "[Epoch 6, Step 100] Loss: 6.8336, Acc: 0.1777\n",
      "[Epoch 6, Step 200] Loss: 6.4333, Acc: 0.2054\n",
      "[Epoch 6, Step 300] Loss: 6.8282, Acc: 0.1754\n",
      "[Epoch 6, Step 400] Loss: 6.6842, Acc: 0.1598\n",
      "[Epoch 6, Step 500] Loss: 6.5491, Acc: 0.1844\n",
      "[Epoch 6, Step 600] Loss: 6.6464, Acc: 0.1767\n",
      "[Epoch 6, Step 700] Loss: 6.7402, Acc: 0.1599\n",
      "[Epoch 6, Step 800] Loss: 6.4453, Acc: 0.1797\n",
      "[Epoch 6, Step 900] Loss: 6.6205, Acc: 0.1771\n",
      "[Epoch 6, Step 1000] Loss: 6.6023, Acc: 0.1769\n",
      "[Epoch 6, Step 1100] Loss: 6.6236, Acc: 0.1810\n",
      "[Epoch 6, Step 1200] Loss: 6.5483, Acc: 0.1897\n",
      "[Epoch 6, Step 1300] Loss: 6.7933, Acc: 0.1173\n",
      "Epoch 6 Completed - Avg Loss: 6.7089, Avg Acc: 0.1649\n",
      "[Epoch 7, Step 0] Loss: 6.7358, Acc: 0.1335\n",
      "[Epoch 7, Step 100] Loss: 6.4905, Acc: 0.1696\n",
      "[Epoch 7, Step 200] Loss: 6.5660, Acc: 0.1778\n",
      "[Epoch 7, Step 300] Loss: 6.4036, Acc: 0.1924\n",
      "[Epoch 7, Step 400] Loss: 6.5816, Acc: 0.1683\n",
      "[Epoch 7, Step 500] Loss: 6.4846, Acc: 0.1740\n",
      "[Epoch 7, Step 600] Loss: 6.3354, Acc: 0.1807\n",
      "[Epoch 7, Step 700] Loss: 6.6330, Acc: 0.1522\n",
      "[Epoch 7, Step 800] Loss: 6.2201, Acc: 0.2013\n",
      "[Epoch 7, Step 900] Loss: 6.4183, Acc: 0.1650\n",
      "[Epoch 7, Step 1000] Loss: 6.4938, Acc: 0.1698\n",
      "[Epoch 7, Step 1100] Loss: 6.6562, Acc: 0.1559\n",
      "[Epoch 7, Step 1200] Loss: 6.5561, Acc: 0.1626\n",
      "[Epoch 7, Step 1300] Loss: 6.5284, Acc: 0.1609\n",
      "Epoch 7 Completed - Avg Loss: 6.4989, Avg Acc: 0.1654\n",
      "[Epoch 8, Step 0] Loss: 6.2841, Acc: 0.1682\n",
      "[Epoch 8, Step 100] Loss: 6.5123, Acc: 0.1491\n",
      "[Epoch 8, Step 200] Loss: 6.4396, Acc: 0.1805\n",
      "[Epoch 8, Step 300] Loss: 6.3328, Acc: 0.1821\n",
      "[Epoch 8, Step 400] Loss: 6.2486, Acc: 0.1810\n",
      "[Epoch 8, Step 500] Loss: 6.4710, Acc: 0.1662\n",
      "[Epoch 8, Step 600] Loss: 6.4615, Acc: 0.1465\n",
      "[Epoch 8, Step 700] Loss: 6.3370, Acc: 0.1644\n",
      "[Epoch 8, Step 800] Loss: 6.2038, Acc: 0.1994\n",
      "[Epoch 8, Step 900] Loss: 6.2356, Acc: 0.1759\n",
      "[Epoch 8, Step 1000] Loss: 6.4753, Acc: 0.1515\n",
      "[Epoch 8, Step 1100] Loss: 6.3821, Acc: 0.1616\n",
      "[Epoch 8, Step 1200] Loss: 6.0425, Acc: 0.2043\n",
      "[Epoch 8, Step 1300] Loss: 6.1407, Acc: 0.1862\n",
      "Epoch 8 Completed - Avg Loss: 6.3277, Avg Acc: 0.1655\n",
      "[Epoch 9, Step 0] Loss: 6.2842, Acc: 0.1558\n",
      "[Epoch 9, Step 100] Loss: 6.2793, Acc: 0.1681\n",
      "[Epoch 9, Step 200] Loss: 6.1145, Acc: 0.1911\n",
      "[Epoch 9, Step 300] Loss: 6.4514, Acc: 0.1415\n",
      "[Epoch 9, Step 400] Loss: 6.2825, Acc: 0.1565\n",
      "[Epoch 9, Step 500] Loss: 6.4230, Acc: 0.1739\n",
      "[Epoch 9, Step 600] Loss: 6.1937, Acc: 0.1721\n",
      "[Epoch 9, Step 700] Loss: 5.9632, Acc: 0.1680\n",
      "[Epoch 9, Step 800] Loss: 6.2038, Acc: 0.1614\n",
      "[Epoch 9, Step 900] Loss: 6.0072, Acc: 0.1719\n",
      "[Epoch 9, Step 1000] Loss: 6.1325, Acc: 0.1616\n",
      "[Epoch 9, Step 1100] Loss: 6.3598, Acc: 0.1525\n",
      "[Epoch 9, Step 1200] Loss: 6.1704, Acc: 0.1780\n",
      "[Epoch 9, Step 1300] Loss: 6.0356, Acc: 0.1868\n",
      "Epoch 9 Completed - Avg Loss: 6.1859, Avg Acc: 0.1660\n",
      "[Epoch 10, Step 0] Loss: 5.8359, Acc: 0.1930\n",
      "[Epoch 10, Step 100] Loss: 6.1462, Acc: 0.1706\n",
      "[Epoch 10, Step 200] Loss: 6.2333, Acc: 0.1508\n",
      "[Epoch 10, Step 300] Loss: 6.3412, Acc: 0.1341\n",
      "[Epoch 10, Step 400] Loss: 6.1055, Acc: 0.1693\n",
      "[Epoch 10, Step 500] Loss: 6.0605, Acc: 0.1532\n",
      "[Epoch 10, Step 600] Loss: 6.1822, Acc: 0.1576\n",
      "[Epoch 10, Step 700] Loss: 6.0194, Acc: 0.1684\n",
      "[Epoch 10, Step 800] Loss: 6.1078, Acc: 0.1548\n",
      "[Epoch 10, Step 900] Loss: 6.0717, Acc: 0.1659\n",
      "[Epoch 10, Step 1000] Loss: 5.9287, Acc: 0.1704\n",
      "[Epoch 10, Step 1100] Loss: 5.9716, Acc: 0.1801\n",
      "[Epoch 10, Step 1200] Loss: 5.8484, Acc: 0.1821\n",
      "[Epoch 10, Step 1300] Loss: 5.8717, Acc: 0.1786\n",
      "Epoch 10 Completed - Avg Loss: 6.0695, Avg Acc: 0.1670\n",
      "[Epoch 11, Step 0] Loss: 6.1819, Acc: 0.1416\n",
      "[Epoch 11, Step 100] Loss: 5.9757, Acc: 0.1738\n",
      "[Epoch 11, Step 200] Loss: 5.9959, Acc: 0.1761\n",
      "[Epoch 11, Step 300] Loss: 5.8704, Acc: 0.1921\n",
      "[Epoch 11, Step 400] Loss: 6.1017, Acc: 0.1680\n",
      "[Epoch 11, Step 500] Loss: 5.8604, Acc: 0.1745\n",
      "[Epoch 11, Step 600] Loss: 6.1852, Acc: 0.1725\n",
      "[Epoch 11, Step 700] Loss: 5.9414, Acc: 0.1650\n",
      "[Epoch 11, Step 800] Loss: 5.8186, Acc: 0.1885\n",
      "[Epoch 11, Step 900] Loss: 5.9784, Acc: 0.1571\n",
      "[Epoch 11, Step 1000] Loss: 5.8821, Acc: 0.1967\n",
      "[Epoch 11, Step 1100] Loss: 6.1667, Acc: 0.1486\n",
      "[Epoch 11, Step 1200] Loss: 5.8180, Acc: 0.1936\n",
      "[Epoch 11, Step 1300] Loss: 6.0463, Acc: 0.1769\n",
      "Epoch 11 Completed - Avg Loss: 5.9724, Avg Acc: 0.1696\n",
      "[Epoch 12, Step 0] Loss: 5.8861, Acc: 0.1494\n",
      "[Epoch 12, Step 100] Loss: 5.8256, Acc: 0.1769\n",
      "[Epoch 12, Step 200] Loss: 5.6398, Acc: 0.2160\n",
      "[Epoch 12, Step 300] Loss: 5.6977, Acc: 0.1627\n",
      "[Epoch 12, Step 400] Loss: 5.8640, Acc: 0.1773\n",
      "[Epoch 12, Step 500] Loss: 5.7100, Acc: 0.1787\n",
      "[Epoch 12, Step 600] Loss: 6.0850, Acc: 0.1839\n",
      "[Epoch 12, Step 700] Loss: 6.0653, Acc: 0.1763\n",
      "[Epoch 12, Step 800] Loss: 6.0105, Acc: 0.1816\n",
      "[Epoch 12, Step 900] Loss: 5.9277, Acc: 0.1614\n",
      "[Epoch 12, Step 1000] Loss: 5.9801, Acc: 0.1549\n",
      "[Epoch 12, Step 1100] Loss: 6.1902, Acc: 0.1496\n",
      "[Epoch 12, Step 1200] Loss: 5.9992, Acc: 0.1644\n",
      "[Epoch 12, Step 1300] Loss: 5.8518, Acc: 0.1826\n",
      "Epoch 12 Completed - Avg Loss: 5.8923, Avg Acc: 0.1735\n",
      "[Epoch 13, Step 0] Loss: 5.7283, Acc: 0.1846\n",
      "[Epoch 13, Step 100] Loss: 5.7553, Acc: 0.1834\n",
      "[Epoch 13, Step 200] Loss: 5.8325, Acc: 0.1747\n",
      "[Epoch 13, Step 300] Loss: 5.7458, Acc: 0.1641\n",
      "[Epoch 13, Step 400] Loss: 5.8587, Acc: 0.1880\n",
      "[Epoch 13, Step 500] Loss: 5.9449, Acc: 0.1706\n",
      "[Epoch 13, Step 600] Loss: 5.8337, Acc: 0.1797\n",
      "[Epoch 13, Step 700] Loss: 5.5561, Acc: 0.2036\n",
      "[Epoch 13, Step 800] Loss: 6.0379, Acc: 0.1636\n",
      "[Epoch 13, Step 900] Loss: 5.7922, Acc: 0.1929\n",
      "[Epoch 13, Step 1000] Loss: 5.8760, Acc: 0.1750\n",
      "[Epoch 13, Step 1100] Loss: 5.9458, Acc: 0.1699\n",
      "[Epoch 13, Step 1200] Loss: 5.9339, Acc: 0.1406\n",
      "[Epoch 13, Step 1300] Loss: 5.9529, Acc: 0.1649\n",
      "Epoch 13 Completed - Avg Loss: 5.8224, Avg Acc: 0.1774\n",
      "[Epoch 14, Step 0] Loss: 5.7005, Acc: 0.2050\n",
      "[Epoch 14, Step 100] Loss: 5.7530, Acc: 0.1730\n",
      "[Epoch 14, Step 200] Loss: 5.8044, Acc: 0.1951\n",
      "[Epoch 14, Step 300] Loss: 5.6854, Acc: 0.1899\n",
      "[Epoch 14, Step 400] Loss: 5.7395, Acc: 0.1836\n",
      "[Epoch 14, Step 500] Loss: 5.7430, Acc: 0.1909\n",
      "[Epoch 14, Step 600] Loss: 5.8268, Acc: 0.1931\n",
      "[Epoch 14, Step 700] Loss: 5.7301, Acc: 0.1865\n",
      "[Epoch 14, Step 800] Loss: 5.5420, Acc: 0.2105\n",
      "[Epoch 14, Step 900] Loss: 5.8436, Acc: 0.1860\n",
      "[Epoch 14, Step 1000] Loss: 5.9111, Acc: 0.1729\n",
      "[Epoch 14, Step 1100] Loss: 5.8945, Acc: 0.1553\n",
      "[Epoch 14, Step 1200] Loss: 5.7750, Acc: 0.1830\n",
      "[Epoch 14, Step 1300] Loss: 5.5975, Acc: 0.1878\n",
      "Epoch 14 Completed - Avg Loss: 5.7641, Avg Acc: 0.1797\n",
      "[Epoch 15, Step 0] Loss: 5.2860, Acc: 0.2124\n",
      "[Epoch 15, Step 100] Loss: 5.7631, Acc: 0.1631\n",
      "[Epoch 15, Step 200] Loss: 5.9074, Acc: 0.1663\n",
      "[Epoch 15, Step 300] Loss: 5.4523, Acc: 0.2295\n",
      "[Epoch 15, Step 400] Loss: 5.8032, Acc: 0.1942\n",
      "[Epoch 15, Step 500] Loss: 5.8791, Acc: 0.1851\n",
      "[Epoch 15, Step 600] Loss: 5.5596, Acc: 0.1797\n",
      "[Epoch 15, Step 700] Loss: 5.6566, Acc: 0.1692\n",
      "[Epoch 15, Step 800] Loss: 5.4995, Acc: 0.1951\n",
      "[Epoch 15, Step 900] Loss: 5.6914, Acc: 0.1694\n",
      "[Epoch 15, Step 1000] Loss: 5.8982, Acc: 0.1588\n",
      "[Epoch 15, Step 1100] Loss: 5.6559, Acc: 0.1941\n",
      "[Epoch 15, Step 1200] Loss: 5.7036, Acc: 0.1836\n",
      "[Epoch 15, Step 1300] Loss: 5.6970, Acc: 0.1865\n",
      "Epoch 15 Completed - Avg Loss: 5.7132, Avg Acc: 0.1805\n",
      "[Epoch 16, Step 0] Loss: 5.5255, Acc: 0.1671\n",
      "[Epoch 16, Step 100] Loss: 5.8941, Acc: 0.1748\n",
      "[Epoch 16, Step 200] Loss: 5.6621, Acc: 0.1607\n",
      "[Epoch 16, Step 300] Loss: 5.8656, Acc: 0.1766\n",
      "[Epoch 16, Step 400] Loss: 5.7683, Acc: 0.1540\n",
      "[Epoch 16, Step 500] Loss: 5.7225, Acc: 0.1675\n",
      "[Epoch 16, Step 600] Loss: 5.6544, Acc: 0.1796\n",
      "[Epoch 16, Step 700] Loss: 5.5527, Acc: 0.1795\n",
      "[Epoch 16, Step 800] Loss: 5.5054, Acc: 0.2044\n",
      "[Epoch 16, Step 900] Loss: 5.6282, Acc: 0.1950\n",
      "[Epoch 16, Step 1000] Loss: 5.7786, Acc: 0.1799\n",
      "[Epoch 16, Step 1100] Loss: 5.4535, Acc: 0.1778\n",
      "[Epoch 16, Step 1200] Loss: 5.5474, Acc: 0.1598\n",
      "[Epoch 16, Step 1300] Loss: 5.4106, Acc: 0.2072\n",
      "Epoch 16 Completed - Avg Loss: 5.6689, Avg Acc: 0.1807\n",
      "[Epoch 17, Step 0] Loss: 5.5616, Acc: 0.2102\n",
      "[Epoch 17, Step 100] Loss: 5.7045, Acc: 0.1727\n",
      "[Epoch 17, Step 200] Loss: 5.7144, Acc: 0.1671\n",
      "[Epoch 17, Step 300] Loss: 5.5555, Acc: 0.1761\n",
      "[Epoch 17, Step 400] Loss: 5.4524, Acc: 0.1983\n",
      "[Epoch 17, Step 500] Loss: 5.5842, Acc: 0.1868\n",
      "[Epoch 17, Step 600] Loss: 5.5228, Acc: 0.1835\n",
      "[Epoch 17, Step 700] Loss: 5.2690, Acc: 0.1988\n",
      "[Epoch 17, Step 800] Loss: 5.6889, Acc: 0.1508\n",
      "[Epoch 17, Step 900] Loss: 5.4177, Acc: 0.2049\n",
      "[Epoch 17, Step 1000] Loss: 5.5430, Acc: 0.1746\n",
      "[Epoch 17, Step 1100] Loss: 5.6229, Acc: 0.1780\n",
      "[Epoch 17, Step 1200] Loss: 5.6978, Acc: 0.1878\n",
      "[Epoch 17, Step 1300] Loss: 5.4996, Acc: 0.1906\n",
      "Epoch 17 Completed - Avg Loss: 5.6305, Avg Acc: 0.1810\n",
      "[Epoch 18, Step 0] Loss: 5.4592, Acc: 0.2009\n",
      "[Epoch 18, Step 100] Loss: 5.6439, Acc: 0.1603\n",
      "[Epoch 18, Step 200] Loss: 5.7644, Acc: 0.1566\n",
      "[Epoch 18, Step 300] Loss: 5.4631, Acc: 0.1985\n",
      "[Epoch 18, Step 400] Loss: 5.4828, Acc: 0.1816\n",
      "[Epoch 18, Step 500] Loss: 5.6676, Acc: 0.1648\n",
      "[Epoch 18, Step 600] Loss: 5.4532, Acc: 0.1835\n",
      "[Epoch 18, Step 700] Loss: 5.6274, Acc: 0.1833\n",
      "[Epoch 18, Step 800] Loss: 5.6411, Acc: 0.1604\n",
      "[Epoch 18, Step 900] Loss: 5.4945, Acc: 0.1698\n",
      "[Epoch 18, Step 1000] Loss: 5.7432, Acc: 0.1726\n",
      "[Epoch 18, Step 1100] Loss: 5.8559, Acc: 0.1962\n",
      "[Epoch 18, Step 1200] Loss: 5.6763, Acc: 0.1717\n",
      "[Epoch 18, Step 1300] Loss: 5.6581, Acc: 0.1642\n",
      "Epoch 18 Completed - Avg Loss: 5.5974, Avg Acc: 0.1812\n",
      "[Epoch 19, Step 0] Loss: 5.4228, Acc: 0.1732\n",
      "[Epoch 19, Step 100] Loss: 5.5945, Acc: 0.1580\n",
      "[Epoch 19, Step 200] Loss: 5.6727, Acc: 0.1695\n",
      "[Epoch 19, Step 300] Loss: 5.0942, Acc: 0.2441\n",
      "[Epoch 19, Step 400] Loss: 6.1284, Acc: 0.1508\n",
      "[Epoch 19, Step 500] Loss: 5.5483, Acc: 0.1809\n",
      "[Epoch 19, Step 600] Loss: 5.3636, Acc: 0.2173\n",
      "[Epoch 19, Step 700] Loss: 5.4837, Acc: 0.1902\n",
      "[Epoch 19, Step 800] Loss: 5.0002, Acc: 0.2161\n",
      "[Epoch 19, Step 900] Loss: 5.7293, Acc: 0.1766\n",
      "[Epoch 19, Step 1000] Loss: 5.5731, Acc: 0.1517\n",
      "[Epoch 19, Step 1100] Loss: 5.5426, Acc: 0.1862\n",
      "[Epoch 19, Step 1200] Loss: 5.5625, Acc: 0.1532\n",
      "[Epoch 19, Step 1300] Loss: 5.7093, Acc: 0.1614\n",
      "Epoch 19 Completed - Avg Loss: 5.5679, Avg Acc: 0.1814\n",
      "[Epoch 20, Step 0] Loss: 5.4268, Acc: 0.1950\n",
      "[Epoch 20, Step 100] Loss: 5.6270, Acc: 0.1799\n",
      "[Epoch 20, Step 200] Loss: 5.4549, Acc: 0.1790\n",
      "[Epoch 20, Step 300] Loss: 5.6095, Acc: 0.1858\n",
      "[Epoch 20, Step 400] Loss: 5.6107, Acc: 0.1663\n",
      "[Epoch 20, Step 500] Loss: 5.5995, Acc: 0.1867\n",
      "[Epoch 20, Step 600] Loss: 5.5358, Acc: 0.1707\n",
      "[Epoch 20, Step 700] Loss: 5.4887, Acc: 0.1771\n",
      "[Epoch 20, Step 800] Loss: 5.3644, Acc: 0.1800\n",
      "[Epoch 20, Step 900] Loss: 5.4511, Acc: 0.1704\n",
      "[Epoch 20, Step 1000] Loss: 5.4291, Acc: 0.1994\n",
      "[Epoch 20, Step 1100] Loss: 5.8701, Acc: 0.1463\n",
      "[Epoch 20, Step 1200] Loss: 5.3634, Acc: 0.1512\n",
      "[Epoch 20, Step 1300] Loss: 5.9139, Acc: 0.1765\n",
      "Epoch 20 Completed - Avg Loss: 5.5431, Avg Acc: 0.1816\n",
      "[Epoch 21, Step 0] Loss: 5.6819, Acc: 0.1800\n",
      "[Epoch 21, Step 100] Loss: 5.6227, Acc: 0.1714\n",
      "[Epoch 21, Step 200] Loss: 5.6997, Acc: 0.1542\n",
      "[Epoch 21, Step 300] Loss: 5.4544, Acc: 0.1754\n",
      "[Epoch 21, Step 400] Loss: 5.6374, Acc: 0.1685\n",
      "[Epoch 21, Step 500] Loss: 5.7045, Acc: 0.1766\n",
      "[Epoch 21, Step 600] Loss: 5.4324, Acc: 0.1868\n",
      "[Epoch 21, Step 700] Loss: 5.3261, Acc: 0.2102\n",
      "[Epoch 21, Step 800] Loss: 5.3790, Acc: 0.1780\n",
      "[Epoch 21, Step 900] Loss: 5.5270, Acc: 0.1783\n",
      "[Epoch 21, Step 1000] Loss: 5.5167, Acc: 0.1582\n",
      "[Epoch 21, Step 1100] Loss: 5.4361, Acc: 0.1708\n",
      "[Epoch 21, Step 1200] Loss: 5.7744, Acc: 0.1659\n",
      "[Epoch 21, Step 1300] Loss: 5.3109, Acc: 0.1932\n",
      "Epoch 21 Completed - Avg Loss: 5.5218, Avg Acc: 0.1823\n",
      "[Epoch 22, Step 0] Loss: 5.5265, Acc: 0.1779\n",
      "[Epoch 22, Step 100] Loss: 5.6575, Acc: 0.1841\n",
      "[Epoch 22, Step 200] Loss: 5.6241, Acc: 0.1740\n",
      "[Epoch 22, Step 300] Loss: 5.9109, Acc: 0.1620\n",
      "[Epoch 22, Step 400] Loss: 5.4193, Acc: 0.1871\n",
      "[Epoch 22, Step 500] Loss: 5.4335, Acc: 0.1919\n",
      "[Epoch 22, Step 600] Loss: 5.3387, Acc: 0.1797\n",
      "[Epoch 22, Step 700] Loss: 5.3256, Acc: 0.2222\n",
      "[Epoch 22, Step 800] Loss: 5.3149, Acc: 0.2205\n",
      "[Epoch 22, Step 900] Loss: 5.6833, Acc: 0.1438\n",
      "[Epoch 22, Step 1000] Loss: 5.4797, Acc: 0.1429\n",
      "[Epoch 22, Step 1100] Loss: 5.4209, Acc: 0.1962\n",
      "[Epoch 22, Step 1200] Loss: 5.4506, Acc: 0.1843\n",
      "[Epoch 22, Step 1300] Loss: 5.3799, Acc: 0.1796\n",
      "Epoch 22 Completed - Avg Loss: 5.4986, Avg Acc: 0.1839\n",
      "[Epoch 23, Step 0] Loss: 5.4926, Acc: 0.1648\n",
      "[Epoch 23, Step 100] Loss: 5.8042, Acc: 0.1585\n",
      "[Epoch 23, Step 200] Loss: 5.7497, Acc: 0.1599\n",
      "[Epoch 23, Step 300] Loss: 5.2667, Acc: 0.2036\n",
      "[Epoch 23, Step 400] Loss: 5.4385, Acc: 0.1822\n",
      "[Epoch 23, Step 500] Loss: 5.3180, Acc: 0.1834\n",
      "[Epoch 23, Step 600] Loss: 5.1803, Acc: 0.1912\n",
      "[Epoch 23, Step 700] Loss: 5.5713, Acc: 0.1771\n",
      "[Epoch 23, Step 800] Loss: 5.6150, Acc: 0.1809\n",
      "[Epoch 23, Step 900] Loss: 5.2939, Acc: 0.1972\n",
      "[Epoch 23, Step 1000] Loss: 5.3808, Acc: 0.1879\n",
      "[Epoch 23, Step 1100] Loss: 5.4246, Acc: 0.1861\n",
      "[Epoch 23, Step 1200] Loss: 5.3964, Acc: 0.1667\n",
      "[Epoch 23, Step 1300] Loss: 5.5443, Acc: 0.1811\n",
      "Epoch 23 Completed - Avg Loss: 5.4819, Avg Acc: 0.1864\n",
      "[Epoch 24, Step 0] Loss: 5.5239, Acc: 0.1740\n",
      "[Epoch 24, Step 100] Loss: 5.4062, Acc: 0.2125\n",
      "[Epoch 24, Step 200] Loss: 5.6323, Acc: 0.1786\n",
      "[Epoch 24, Step 300] Loss: 5.4075, Acc: 0.1935\n",
      "[Epoch 24, Step 400] Loss: 5.3610, Acc: 0.2255\n",
      "[Epoch 24, Step 500] Loss: 5.4259, Acc: 0.1578\n",
      "[Epoch 24, Step 600] Loss: 5.5865, Acc: 0.1766\n",
      "[Epoch 24, Step 700] Loss: 5.6996, Acc: 0.1706\n",
      "[Epoch 24, Step 800] Loss: 5.2442, Acc: 0.2080\n",
      "[Epoch 24, Step 900] Loss: 5.0371, Acc: 0.2143\n",
      "[Epoch 24, Step 1000] Loss: 5.2469, Acc: 0.2105\n",
      "[Epoch 24, Step 1100] Loss: 5.6219, Acc: 0.1762\n",
      "[Epoch 24, Step 1200] Loss: 5.5836, Acc: 0.1837\n",
      "[Epoch 24, Step 1300] Loss: 5.2997, Acc: 0.2153\n",
      "Epoch 24 Completed - Avg Loss: 5.4640, Avg Acc: 0.1889\n",
      "[Epoch 25, Step 0] Loss: 5.0588, Acc: 0.2525\n",
      "[Epoch 25, Step 100] Loss: 5.3540, Acc: 0.1976\n",
      "[Epoch 25, Step 200] Loss: 5.2149, Acc: 0.2131\n",
      "[Epoch 25, Step 300] Loss: 5.4496, Acc: 0.1966\n",
      "[Epoch 25, Step 400] Loss: 5.4271, Acc: 0.2169\n",
      "[Epoch 25, Step 500] Loss: 5.5847, Acc: 0.1682\n",
      "[Epoch 25, Step 600] Loss: 5.6135, Acc: 0.1820\n",
      "[Epoch 25, Step 700] Loss: 5.4830, Acc: 0.2117\n",
      "[Epoch 25, Step 800] Loss: 5.8210, Acc: 0.1722\n",
      "[Epoch 25, Step 900] Loss: 5.6254, Acc: 0.1771\n",
      "[Epoch 25, Step 1000] Loss: 5.6738, Acc: 0.1528\n",
      "[Epoch 25, Step 1100] Loss: 5.5601, Acc: 0.1694\n",
      "[Epoch 25, Step 1200] Loss: 5.3738, Acc: 0.1989\n",
      "[Epoch 25, Step 1300] Loss: 5.5343, Acc: 0.1827\n",
      "Epoch 25 Completed - Avg Loss: 5.4479, Avg Acc: 0.1912\n",
      "CPU times: total: 43min 37s\n",
      "Wall time: 7min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=25,  # 원하는 에폭 수\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07ed3a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(model, sentence, tokenizer, device='cpu'):\n",
    "    START_TOKEN = tokenizer.bos_id()\n",
    "    END_TOKEN = tokenizer.eos_id()\n",
    "    MAX_LENGTH = 40\n",
    "\n",
    "\n",
    "    # 전처리\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 레이블 토큰 추가 (기본값: label 0)\n",
    "    label_id = tokenizer.piece_to_id('<label_0>')\n",
    "\n",
    "    # 인코더 입력: [LABEL] + [START] + 인코딩 + [END]\n",
    "    enc_input_ids = [label_id] + [START_TOKEN] + tokenizer.encode(sentence) + [END_TOKEN]\n",
    "    # 차원 확장: (batch_size=1, seq_len)\n",
    "    enc_input = torch.tensor([enc_input_ids], dtype=torch.long, device=device)\n",
    "\n",
    "    # 디코더 입력(dec_input)을 START_TOKEN만 포함한 상태로 시작\n",
    "    dec_input = torch.tensor([[START_TOKEN]], dtype=torch.long, device=device)\n",
    "\n",
    "    model.eval()  # 모델 평가 모드\n",
    "    with torch.no_grad():\n",
    "        for i in range(MAX_LENGTH):\n",
    "            # 모델 forward: (enc_input, dec_input) -> (batch_size=1, seq_len, vocab_size)\n",
    "            logits = model(enc_input, dec_input)\n",
    "\n",
    "            # 마지막 타임스텝의 예측만 추출: shape (1, 1, vocab_size)\n",
    "            # logits[:, -1, :] -> (1, vocab_size)\n",
    "            last_step_logits = logits[:, -1, :]\n",
    "\n",
    "            # argmax로 가장 높은 확률의 토큰 선택\n",
    "            predicted_id = torch.argmax(last_step_logits, dim=-1)  # shape: (1,)\n",
    "\n",
    "            # 종료 토큰이면 중단\n",
    "            if predicted_id.item() == END_TOKEN:\n",
    "                break\n",
    "\n",
    "            # 디코더 입력(dec_input)에 예측 토큰을 이어붙임\n",
    "            predicted_id = predicted_id.unsqueeze(0)  # shape (1,1)\n",
    "            dec_input = torch.cat([dec_input, predicted_id], dim=1)\n",
    "\n",
    "    # 최종 시퀀스: dec_input: (1, seq_len)에서 (seq_len,)로\n",
    "    output_sequence = dec_input.squeeze(0).tolist()  # e.g. [START_TOKEN, ..., 토큰들...]\n",
    "\n",
    "    return output_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "119aba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, sentence, tokenizer, device='cpu'):\n",
    "    # 디코더 인퍼런스 -> 예측된 토큰 시퀀스\n",
    "    output_seq = decoder_inference(model, sentence, tokenizer, device=device)\n",
    "\n",
    "    # 토크나이저로 디코딩 (패딩, START/END 토큰 등은 제외하거나 처리)\n",
    "    # 여기서는 단순히 tokenizer.decode() 직접 호출\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [token for token in output_seq if token < tokenizer.GetPieceSize()]\n",
    "    )\n",
    "\n",
    "    print(\"입력 :\", sentence)\n",
    "    print(\"출력 :\", predicted_sentence)\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2de00b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : Where have you been?\n",
      "출력 : i m .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i m .'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Where have you been?'\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cef938cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : It's a trap\n",
      "출력 : i m .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i m .'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"It's a trap\"\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44cd5949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : are you retrard?\n",
      "출력 : i m .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i m .'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"are you retrard?\"\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jedi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
