{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "fe31ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import sentencepiece as spm\n",
    "\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "# import urllib.request\n",
    "# import zipfile\n",
    "# import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "max_seq_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "58c9c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.position = position\n",
    "\n",
    "        self.pos_encoding = self._build_pos_encoding(position, d_model)\n",
    "\n",
    "    def _get_angles(self, position, i, d_model):\n",
    "        return 1.0 / (10000.0 ** ((2.0 * (i // 2)) / d_model)) * position\n",
    "\n",
    "    def _build_pos_encoding(self, position, d_model):\n",
    "        pos = torch.arange(position, dtype=torch.float32).unsqueeze(1)\n",
    "        i = torch.arange(d_model, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        angle_rads = self._get_angles(pos, i, d_model)\n",
    "        sines = torch.sin(angle_rads[:, 0::2])\n",
    "        cosines = torch.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = torch.zeros(position, d_model)\n",
    "        pos_encoding[:, 0::2] = sines\n",
    "        pos_encoding[:, 1::2] = cosines\n",
    "\n",
    "        pos_encoding = pos_encoding.unsqueeze(0)  # shape: [1, position, d_model]\n",
    "        return pos_encoding\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pos_encoding[:, :x.size(1), :].to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "2bf3ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "\n",
    "    # 1) Q와 K의 내적을 통해 score(유사도) 계산\n",
    "    # key.transpose(-1, -2): (batch_size, heads, depth, seq_len)\n",
    "    # matmul 결과 shape: (batch_size, heads, seq_len, seq_len)\n",
    "    matmul_qk = torch.matmul(query, key.transpose(-1, -2))\n",
    "\n",
    "    # 2) depth에 따라 정규화\n",
    "    depth = key.size(-1)  # depth = d_model / heads\n",
    "    logits = matmul_qk / math.sqrt(depth)\n",
    "\n",
    "    # 3) 마스크가 주어졌다면 -1e9(아주 작은 값)를 더해 소프트맥스에서 제외시키도록 함\n",
    "    if mask is not None:\n",
    "        # 텐서플로우: logits += (mask * -1e9)\n",
    "        # 파이토치 동일 적용\n",
    "        logits = logits + (mask * -1e9)\n",
    "\n",
    "    # 4) 소프트맥스 계산해 attention weights 생성\n",
    "    attention_weights = F.softmax(logits, dim=-1)\n",
    "\n",
    "    # 5) attention weights와 value의 내적\n",
    "    output = torch.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "ef3a883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # d_model은 num_heads로 나누어떨어져야 함\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        # 파이토치에서 Dense는 nn.Linear로 대응\n",
    "        self.query_dense = nn.Linear(d_model, d_model)\n",
    "        self.key_dense = nn.Linear(d_model, d_model)\n",
    "        self.value_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.out_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, d_model)\n",
    "        => (batch_size, num_heads, seq_len, depth) 형태로 변환\n",
    "        \"\"\"\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
    "        x = x.permute(0, 2, 1, 3)  # (batch_size, num_heads, seq_len, depth)\n",
    "        return x\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "        query, key, value: (batch_size, seq_len, d_model)\n",
    "        mask: (batch_size, 1, seq_len, seq_len) 등으로 broadcast 가능하도록 구성\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # Q, K, V에 각각 Linear 적용\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # Head 분할\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, depth) -> (batch_size, seq_len, num_heads, depth)\n",
    "        scaled_attention = scaled_attention.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "        # 다시 (batch_size, seq_len, d_model)로 합치기\n",
    "        concat_attention = scaled_attention.view(batch_size, -1, self.d_model)\n",
    "\n",
    "        # 최종 Dense\n",
    "        output = self.out_dense(concat_attention)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "a0703229",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)  # 이전에 구현한 MHA\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 피드포워드 부분 (Dense -> ReLU -> Dense)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, d_model)\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # (1) 멀티 헤드 어텐션 (셀프 어텐션)\n",
    "        attn_output = self.mha(x, x, x, mask)  # (batch_size, seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.norm1(x + attn_output)     # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # (2) 피드포워드 신경망\n",
    "        ffn_output = self.ffn(out1)            # (batch_size, seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.norm2(out1 + ffn_output)   # 잔차 연결 + LayerNorm\n",
    "\n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "71a33ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 ff_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # (1) 임베딩 레이어\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩\n",
    "        \n",
    "        #self.pos_encoding = PositionalEncoding(position=vocab_size, d_model=d_model)\n",
    "        self.pos_encoding = PositionalEncoding(position=max_seq_length, d_model=d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # (3) EncoderLayer 쌓기\n",
    "        self.enc_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # (1) 임베딩 & sqrt(d_model)로 스케일링\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩 적용 + 드롭아웃\n",
    "        x = self.pos_encoding(x)  # shape: (batch_size, seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # (3) num_layers만큼 쌓아올린 EncoderLayer 통과\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "83aadab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        # 첫 번째 서브 레이어 (디코더 내부 셀프 어텐션)\n",
    "        self.self_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 두 번째 서브 레이어 (인코더-디코더 어텐션)\n",
    "        self.encdec_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 세 번째 서브 레이어 (피드포워드 네트워크)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),  # Dense(units=ff_dim)\n",
    "            nn.ReLU(),                   # activation='relu'\n",
    "            nn.Linear(ff_dim, d_model)   # Dense(units=d_model)\n",
    "        )\n",
    "        self.norm3 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 드롭아웃\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_outputs, look_ahead_mask=None, padding_mask=None):\n",
    "        # 1) 셀프 어텐션 (디코더 내부)\n",
    "        self_attn_out = self.self_mha(x, x, x, mask=look_ahead_mask)\n",
    "        self_attn_out = self.dropout1(self_attn_out)\n",
    "        out1 = self.norm1(x + self_attn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # 2) 인코더-디코더 어텐션\n",
    "        encdec_attn_out = self.encdec_mha(out1, enc_outputs, enc_outputs, mask=padding_mask)\n",
    "        encdec_attn_out = self.dropout2(encdec_attn_out)\n",
    "        out2 = self.norm2(out1 + encdec_attn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # 3) 피드포워드 (Dense -> ReLU -> Dense)\n",
    "        ffn_out = self.ffn(out2)\n",
    "        ffn_out = self.dropout3(ffn_out)\n",
    "        out3 = self.norm3(out2 + ffn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "cf3e9d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 ff_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # (1) 임베딩 레이어\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩\n",
    "        # 실제 학습 시에는 최대 시퀀스 길이에 맞추어 쓰기도 함\n",
    "        #self.pos_encoding = PositionalEncoding(position=vocab_size, d_model=d_model)\n",
    "        self.pos_encoding = PositionalEncoding(position=max_seq_length, d_model=d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # (3) DecoderLayer 쌓기\n",
    "        self.dec_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, enc_outputs, look_ahead_mask=None, padding_mask=None):\n",
    "        # (1) 임베딩 + sqrt(d_model)로 스케일링\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩 + 드롭아웃\n",
    "        x = self.pos_encoding(x)    # (batch_size, tgt_seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # (3) num_layers만큼 쌓인 DecoderLayer 통과\n",
    "        for layer in self.dec_layers:\n",
    "            x = layer(x, enc_outputs, look_ahead_mask, padding_mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "7d32b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 폴더 경로\n",
    "path = 'ChatbotData.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "4f513a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # 1. 유니코드 정규화\n",
    "    sentence = unicodedata.normalize(\"NFC\", sentence)\n",
    "\n",
    "    # 2. 문장부호 앞뒤에 공백 삽입\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
    "\n",
    "    # 3. 허용 문자만 유지 (한글, 자모, 영문, 숫자, 공백, 주요 문장부호)\n",
    "    sentence = re.sub(r\"[^가-힣ㄱ-ㅎㅏ-ㅣA-Za-z0-9?.!,~… ]\", \" \", sentence)\n",
    "\n",
    "    # 4. 감정 표현 반복 상한 (4개 이상 → 2개)\n",
    "    sentence = re.sub(r'(ㅋ)\\1{3,}', r'\\1\\1', sentence)\n",
    "    sentence = re.sub(r'(ㅎ)\\1{3,}', r'\\1\\1', sentence)\n",
    "    sentence = re.sub(r'(ㅠ)\\1{3,}', r'\\1\\1', sentence)\n",
    "    sentence = re.sub(r'(ㅜ)\\1{3,}', r'\\1\\1', sentence)\n",
    "\n",
    "    # 5. 공백 정리\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence).strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "4ece1f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chatbot_csv(path,preprocess_sentence):\n",
    "    \"\"\"\n",
    "    반환: [(Q_clean, A_clean, label), ...]\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    qs = df[\"Q\"].astype(str).map(preprocess_sentence)\n",
    "    as_ = df[\"A\"].astype(str).map(preprocess_sentence)\n",
    "    labels = df[\"label\"].astype(int)\n",
    "    return list(zip(qs, as_, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "1fdd55dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    # x == 0 위치를 찾아 float형 1로 변환\n",
    "    mask = (x == 0).float()\n",
    "    # (batch_size, seq_len) -> (batch_size, 1, 1, seq_len)\n",
    "    mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "108ff8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = x.size(1)\n",
    "\n",
    "    # (seq_len, seq_len) 크기의 하삼각 행렬(tril) 생성 후 1에서 빼서\n",
    "    # 상삼각이 1, 하삼각(자기 자신 포함)이 0이 되도록 설정\n",
    "    # => 미래 토큰(자신 인덱스보다 큰 위치) 마스킹\n",
    "    look_ahead_mask = 1 - torch.tril(torch.ones((seq_len, seq_len)))\n",
    "\n",
    "    # 패딩 마스크 생성 (shape: (batch_size, 1, 1, seq_len))\n",
    "    padding_mask = create_padding_mask(x)\n",
    "\n",
    "    # look_ahead_mask: (seq_len, seq_len) -> (1, seq_len, seq_len)\n",
    "    look_ahead_mask = look_ahead_mask.unsqueeze(0)\n",
    "    # -> (1, seq_len, seq_len) -> (1, 1, seq_len, seq_len)\n",
    "    look_ahead_mask = look_ahead_mask.unsqueeze(1)\n",
    "    look_ahead_mask = look_ahead_mask.to(x.device)\n",
    "\n",
    "    # look-ahead 마스크와 패딩 마스크를 합성 (둘 중 하나라도 1이면 마스킹)\n",
    "    # 최종 shape은 브로드캐스팅으로 (batch_size, 1, seq_len, seq_len)\n",
    "    combined_mask = torch.max(look_ahead_mask, padding_mask)\n",
    "    return combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "487105d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_corpus.txt 생성 완료\n"
     ]
    }
   ],
   "source": [
    "data = load_chatbot_csv(path, preprocess_sentence)\n",
    "\n",
    "with open(\"clean_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for q, a, label in data:\n",
    "        if q and a:\n",
    "            f.write(f\"{label}\\t{q}\\t{a}\\n\")\n",
    "\n",
    "print(\"clean_corpus.txt 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "76af4f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train(\n",
    "    input='clean_corpus.txt',\n",
    "    model_prefix=\"chatbot_spm\",\n",
    "    vocab_size=16000,\n",
    "    character_coverage=0.9995,\n",
    "    model_type=\"bpe\",  # 한국어면 unigram도 가능\n",
    "    max_sentence_length=999999,\n",
    "\n",
    "    # 특수 토큰 ID 설정\n",
    "    pad_id=0,   # <pad>\n",
    "    unk_id=1,   # <unk>\n",
    "    bos_id=2,   # <s>\n",
    "    eos_id=3,   # </s>\n",
    "\n",
    "    # label을 포함한 사용자 정의 토큰\n",
    "    user_defined_symbols=[\n",
    "        \"<label_0>\", \"<label_1>\", \"<label_2>\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "fc77c764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"chatbot_spm.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "95c1a511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5 6\n"
     ]
    }
   ],
   "source": [
    "print(sp.piece_to_id(\"<label_0>\"), sp.piece_to_id(\"<label_1>\"), sp.piece_to_id(\"<label_2>\"))\n",
    "\n",
    "# label 0,1,2 가 토큰 4,5,6에 매핑됨을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "ee975af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self, data, sp, max_length=40):\n",
    "        self.sp = sp\n",
    "        self.max_length = max_length\n",
    "        self.data = []\n",
    "\n",
    "        # spm 모델에 정의된 토큰 ID를 동적으로 가져오기\n",
    "        self.label_map = {\n",
    "            0: self.sp.piece_to_id('<label_0>'),\n",
    "            1: self.sp.piece_to_id('<label_1>'),\n",
    "            2: self.sp.piece_to_id('<label_2>')\n",
    "        }\n",
    "\n",
    "        \n",
    "        for q, a, label in data:\n",
    "            bos_id = self.sp.bos_id()\n",
    "            eos_id = self.sp.eos_id()\n",
    "            label_token = self.label_map[label]\n",
    "\n",
    "            q_ids = self.sp.encode_as_ids(q)\n",
    "            a_ids = self.sp.encode_as_ids(a)\n",
    "\n",
    "            q_tokens = [label_token] + [bos_id] + q_ids + [eos_id]\n",
    "            a_tokens = [bos_id] + a_ids + [eos_id]\n",
    "\n",
    "            if len(q_tokens) > self.max_length or len(a_tokens) > self.max_length:\n",
    "                continue\n",
    "\n",
    "            q_tokens += [self.sp.pad_id()] * (self.max_length - len(q_tokens))\n",
    "            a_tokens += [self.sp.pad_id()] * (self.max_length - len(a_tokens))\n",
    "\n",
    "            dec_input = a_tokens[:-1]\n",
    "            target = a_tokens[1:]\n",
    "\n",
    "            self.data.append({\n",
    "                \"enc_input\": q_tokens,\n",
    "                \"dec_input\": dec_input,\n",
    "                \"target\": target\n",
    "            })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        enc_input = torch.tensor(sample[\"enc_input\"], dtype=torch.long)\n",
    "        dec_input = torch.tensor(sample[\"dec_input\"], dtype=torch.long)\n",
    "        target = torch.tensor(sample[\"target\"], dtype=torch.long)\n",
    "        return enc_input, dec_input, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "6146841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_chatbot_csv(path, preprocess_sentence)\n",
    "dataset = ChatbotDataset(data, sp, max_length=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "7db03529",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "38786e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40])\n",
      "torch.Size([32, 39])\n",
      "torch.Size([32, 39])\n"
     ]
    }
   ],
   "source": [
    "for encoder_input, decoder_input, decoder_label in dataloader:\n",
    "    print(encoder_input.size())\n",
    "    print(decoder_input.size())\n",
    "    print(decoder_label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "8f63da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,      # 인코더/디코더 층 수\n",
    "                 units,           # feed-forward 네트워크의 중간 차원(ff_dim)\n",
    "                 d_model,         # 임베딩 및 내부 표현 차원\n",
    "                 num_heads,       # 멀티헤드 어텐션의 헤드 수\n",
    "                 dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        # 인코더\n",
    "        self.encoder = Encoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # 디코더\n",
    "        self.decoder = Decoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # 최종 출력층: (d_model) -> (vocab_size)\n",
    "        self.final_linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        # 참고: 텐서플로우 코드의 `name=\"transformer\"`는 파이토치에선 보통 사용 안 함\n",
    "\n",
    "    def forward(self, inputs, dec_inputs):\n",
    "        # 1) 인코더 패딩 마스크 생성\n",
    "        enc_padding_mask = create_padding_mask(inputs)     # shape (batch_size, 1, 1, src_seq_len)\n",
    "\n",
    "        # 2) 디코더 look-ahead + 패딩 마스크\n",
    "        look_ahead_mask = create_look_ahead_mask(dec_inputs)  # shape (batch_size, 1, tgt_seq_len, tgt_seq_len)\n",
    "\n",
    "        # 3) 디코더에서 인코더 출력 쪽을 마스킹할 때 쓸 패딩 마스크\n",
    "        dec_padding_mask = create_padding_mask(inputs)        # shape (batch_size, 1, 1, src_seq_len)\n",
    "\n",
    "        # 4) 인코더 수행\n",
    "        enc_outputs = self.encoder(\n",
    "            x=inputs,\n",
    "            mask=enc_padding_mask\n",
    "        )  # shape: (batch_size, src_seq_len, d_model)\n",
    "\n",
    "        # 5) 디코더 수행\n",
    "        dec_outputs = self.decoder(\n",
    "            x=dec_inputs,           # (batch_size, tgt_seq_len)\n",
    "            enc_outputs=enc_outputs,# (batch_size, src_seq_len, d_model)\n",
    "            look_ahead_mask=look_ahead_mask,\n",
    "            padding_mask=dec_padding_mask\n",
    "        )  # shape: (batch_size, tgt_seq_len, d_model)\n",
    "\n",
    "        # 6) 최종 Dense (vocab_size)\n",
    "        logits = self.final_linear(dec_outputs)  # (batch_size, tgt_seq_len, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "507aaaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(16000, 512)\n",
      "    (pos_encoding): PositionalEncoding()\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (enc_layers): ModuleList(\n",
      "      (0-3): 4 x EncoderLayer(\n",
      "        (mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (key_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (value_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(16000, 512)\n",
      "    (pos_encoding): PositionalEncoding()\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (dec_layers): ModuleList(\n",
      "      (0-3): 4 x DecoderLayer(\n",
      "        (self_mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (key_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (value_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (encdec_mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (key_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (value_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm3): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (dropout3): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_linear): Linear(in_features=512, out_features=16000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 예: 하이퍼파라미터 설정\n",
    "NUM_LAYERS = 4     # 인코더/디코더 층 수\n",
    "D_MODEL = 512      # 임베딩 및 내부 표현 차원\n",
    "NUM_HEADS = 8      # 멀티헤드 어텐션에서의 헤드 수\n",
    "UNITS = 2048        # 피드포워드 신경망의 은닉 차원\n",
    "DROPOUT = 0.2      # 드롭아웃 비율\n",
    "VOCAB_SIZE = 16000 # 단어 집합 크기(예시)\n",
    "\n",
    "# 모델 생성\n",
    "model = Transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "af03d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(ignore_index=sp.pad_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "4eb312cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 수정된 학습률 함수\n",
    "'''\n",
    "def get_lr_lambda(d_model, warmup_steps=4000):\n",
    "    d_model = float(d_model)\n",
    "    def lr_lambda(step):\n",
    "        step = max(step, 1)  # 0으로 나누는 것 방지\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (warmup_steps ** -1.5)\n",
    "        return (d_model ** -0.5) * min(arg1, arg2) * 10  # 스케일 증가\n",
    "    return lr_lambda\n",
    "'''\n",
    "def get_lr_lambda(d_model, warmup_steps=2000):\n",
    "    d_model = float(d_model)\n",
    "    def lr_lambda(step):\n",
    "        step = max(step, 1)\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (warmup_steps ** -1.5)\n",
    "        return (d_model ** -0.5) * min(arg1, arg2) * 15  # 10→15\n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "57736254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "d_model = 512\n",
    "warmup_steps = 4000\n",
    "total_steps = 200000  # 총 학습 스텝\n",
    "\n",
    "# 학습률 스케줄 시각화\n",
    "steps = np.arange(1, total_steps + 1)\n",
    "learning_rates = [get_lr_lambda(d_model, warmup_steps)(step) for step in steps]\n",
    "\n",
    "# 그래프 출력\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, learning_rates, label=\"Learning Rate\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Transformer Learning Rate Schedule\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "3201c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer 정의\n",
    "optimizer = optim.AdamW(model.parameters(), betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "# Scheduler 정의\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=get_lr_lambda(D_MODEL, warmup_steps=2000))\n",
    "\n",
    "def accuracy_function(y_pred, y_true, pad_id=0):\n",
    "    \"\"\"\n",
    "    y_pred: (batch_size, seq_len, vocab_size)\n",
    "    y_true: (batch_size, seq_len)\n",
    "    \"\"\"\n",
    "    preds = y_pred.argmax(dim=-1)  # (batch_size, seq_len)\n",
    "    mask = (y_true != pad_id)\n",
    "    correct = (preds == y_true) & mask\n",
    "    acc = correct.float().sum() / mask.float().sum()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "deb05173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "68d90fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, batch, optimizer, loss_function, device):\n",
    "    model.train()\n",
    "    enc_input, dec_input, target = [x.to(device) for x in batch]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 모델 포워드 패스\n",
    "    logits = model(enc_input, dec_input)  # (batch_size, seq_len, vocab_size)\n",
    "\n",
    "    # Loss 계산 (패딩 토큰 무시)\n",
    "    loss = loss_function(logits.permute(0, 2, 1), target)  # (batch_size, vocab_size, seq_len) 필요\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), accuracy_function(logits, target, pad_id=sp.pad_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "69892077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_function, scheduler, num_epochs, device):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss, total_acc = 0, 0\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            loss, acc = train_step(model, batch, optimizer, loss_function, device)\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "\n",
    "            # 일정 스텝마다 로그 출력\n",
    "            if step % 100 == 0:\n",
    "                print(f\"[Epoch {epoch+1}, Step {step}] Loss: {loss:.4f}, Acc: {acc:.4f}\")\n",
    "\n",
    "            # 학습률 스케줄러 업데이트\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_acc = total_acc / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1} Completed - Avg Loss: {avg_loss:.4f}, Avg Acc: {avg_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "512c36bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Step 0] Loss: 9.8173, Acc: 0.0000\n",
      "[Epoch 1, Step 100] Loss: 9.3410, Acc: 0.0391\n",
      "[Epoch 1, Step 200] Loss: 8.1404, Acc: 0.3085\n",
      "[Epoch 1, Step 300] Loss: 7.5706, Acc: 0.2808\n",
      "Epoch 1 Completed - Avg Loss: 8.4306, Avg Acc: 0.2040\n",
      "[Epoch 2, Step 0] Loss: 7.0118, Acc: 0.3228\n",
      "[Epoch 2, Step 100] Loss: 6.8838, Acc: 0.3231\n",
      "[Epoch 2, Step 200] Loss: 6.7008, Acc: 0.3263\n",
      "[Epoch 2, Step 300] Loss: 6.9791, Acc: 0.2603\n",
      "Epoch 2 Completed - Avg Loss: 6.7315, Avg Acc: 0.3243\n",
      "[Epoch 3, Step 0] Loss: 6.7654, Acc: 0.3010\n",
      "[Epoch 3, Step 100] Loss: 6.2028, Acc: 0.3386\n",
      "[Epoch 3, Step 200] Loss: 5.8673, Acc: 0.3750\n",
      "[Epoch 3, Step 300] Loss: 6.0264, Acc: 0.3492\n",
      "Epoch 3 Completed - Avg Loss: 6.2687, Avg Acc: 0.3261\n",
      "[Epoch 4, Step 0] Loss: 5.8868, Acc: 0.3568\n",
      "[Epoch 4, Step 100] Loss: 5.8396, Acc: 0.3462\n",
      "[Epoch 4, Step 200] Loss: 5.9600, Acc: 0.3098\n",
      "[Epoch 4, Step 300] Loss: 5.6495, Acc: 0.3147\n",
      "Epoch 4 Completed - Avg Loss: 5.9029, Avg Acc: 0.3302\n",
      "[Epoch 5, Step 0] Loss: 5.5708, Acc: 0.3608\n",
      "[Epoch 5, Step 100] Loss: 5.3433, Acc: 0.3714\n",
      "[Epoch 5, Step 200] Loss: 5.6425, Acc: 0.3455\n",
      "[Epoch 5, Step 300] Loss: 5.9782, Acc: 0.3074\n",
      "Epoch 5 Completed - Avg Loss: 5.6414, Avg Acc: 0.3401\n",
      "[Epoch 6, Step 0] Loss: 5.5093, Acc: 0.3543\n",
      "[Epoch 6, Step 100] Loss: 5.4861, Acc: 0.3476\n",
      "[Epoch 6, Step 200] Loss: 5.3787, Acc: 0.3476\n",
      "[Epoch 6, Step 300] Loss: 5.7453, Acc: 0.3235\n",
      "Epoch 6 Completed - Avg Loss: 5.4599, Avg Acc: 0.3454\n",
      "[Epoch 7, Step 0] Loss: 5.1953, Acc: 0.3617\n",
      "[Epoch 7, Step 100] Loss: 5.1404, Acc: 0.3777\n",
      "[Epoch 7, Step 200] Loss: 5.5349, Acc: 0.3111\n",
      "[Epoch 7, Step 300] Loss: 5.5458, Acc: 0.3186\n",
      "Epoch 7 Completed - Avg Loss: 5.3145, Avg Acc: 0.3494\n",
      "[Epoch 8, Step 0] Loss: 5.0937, Acc: 0.3645\n",
      "[Epoch 8, Step 100] Loss: 5.3048, Acc: 0.3723\n",
      "[Epoch 8, Step 200] Loss: 5.2464, Acc: 0.3552\n",
      "[Epoch 8, Step 300] Loss: 5.1373, Acc: 0.3490\n",
      "Epoch 8 Completed - Avg Loss: 5.1916, Avg Acc: 0.3532\n",
      "[Epoch 9, Step 0] Loss: 5.2548, Acc: 0.3252\n",
      "[Epoch 9, Step 100] Loss: 5.0285, Acc: 0.3497\n",
      "[Epoch 9, Step 200] Loss: 4.8720, Acc: 0.3925\n",
      "[Epoch 9, Step 300] Loss: 5.0961, Acc: 0.3663\n",
      "Epoch 9 Completed - Avg Loss: 5.0850, Avg Acc: 0.3570\n",
      "[Epoch 10, Step 0] Loss: 5.2356, Acc: 0.3333\n",
      "[Epoch 10, Step 100] Loss: 4.9092, Acc: 0.3764\n",
      "[Epoch 10, Step 200] Loss: 5.4013, Acc: 0.3184\n",
      "[Epoch 10, Step 300] Loss: 5.0714, Acc: 0.3382\n",
      "Epoch 10 Completed - Avg Loss: 4.9908, Avg Acc: 0.3602\n",
      "[Epoch 11, Step 0] Loss: 4.6101, Acc: 0.3838\n",
      "[Epoch 11, Step 100] Loss: 5.0930, Acc: 0.3474\n",
      "[Epoch 11, Step 200] Loss: 4.7412, Acc: 0.3881\n",
      "[Epoch 11, Step 300] Loss: 4.9207, Acc: 0.3817\n",
      "Epoch 11 Completed - Avg Loss: 4.9055, Avg Acc: 0.3641\n",
      "[Epoch 12, Step 0] Loss: 4.8130, Acc: 0.3465\n",
      "[Epoch 12, Step 100] Loss: 4.7079, Acc: 0.3789\n",
      "[Epoch 12, Step 200] Loss: 5.0474, Acc: 0.3364\n",
      "[Epoch 12, Step 300] Loss: 4.9254, Acc: 0.3529\n",
      "Epoch 12 Completed - Avg Loss: 4.8283, Avg Acc: 0.3685\n",
      "[Epoch 13, Step 0] Loss: 4.7372, Acc: 0.3763\n",
      "[Epoch 13, Step 100] Loss: 4.7551, Acc: 0.3590\n",
      "[Epoch 13, Step 200] Loss: 4.5600, Acc: 0.3990\n",
      "[Epoch 13, Step 300] Loss: 4.8058, Acc: 0.3719\n",
      "Epoch 13 Completed - Avg Loss: 4.7538, Avg Acc: 0.3723\n",
      "[Epoch 14, Step 0] Loss: 4.7157, Acc: 0.3578\n",
      "[Epoch 14, Step 100] Loss: 4.1800, Acc: 0.4483\n",
      "[Epoch 14, Step 200] Loss: 4.4139, Acc: 0.4118\n",
      "[Epoch 14, Step 300] Loss: 4.6201, Acc: 0.3958\n",
      "Epoch 14 Completed - Avg Loss: 4.6904, Avg Acc: 0.3763\n",
      "[Epoch 15, Step 0] Loss: 4.6561, Acc: 0.3781\n",
      "[Epoch 15, Step 100] Loss: 4.6958, Acc: 0.3744\n",
      "[Epoch 15, Step 200] Loss: 4.4769, Acc: 0.3939\n",
      "[Epoch 15, Step 300] Loss: 4.8191, Acc: 0.3526\n",
      "Epoch 15 Completed - Avg Loss: 4.6311, Avg Acc: 0.3801\n",
      "[Epoch 16, Step 0] Loss: 4.5163, Acc: 0.3958\n",
      "[Epoch 16, Step 100] Loss: 4.2763, Acc: 0.4105\n",
      "[Epoch 16, Step 200] Loss: 4.8072, Acc: 0.3858\n",
      "[Epoch 16, Step 300] Loss: 4.3835, Acc: 0.4477\n",
      "Epoch 16 Completed - Avg Loss: 4.5738, Avg Acc: 0.3839\n",
      "[Epoch 17, Step 0] Loss: 4.4881, Acc: 0.3989\n",
      "[Epoch 17, Step 100] Loss: 4.5698, Acc: 0.3676\n",
      "[Epoch 17, Step 200] Loss: 4.4452, Acc: 0.3901\n",
      "[Epoch 17, Step 300] Loss: 4.7505, Acc: 0.3750\n",
      "Epoch 17 Completed - Avg Loss: 4.5236, Avg Acc: 0.3866\n",
      "[Epoch 18, Step 0] Loss: 4.3842, Acc: 0.4036\n",
      "[Epoch 18, Step 100] Loss: 4.2377, Acc: 0.4300\n",
      "[Epoch 18, Step 200] Loss: 4.9535, Acc: 0.3472\n",
      "[Epoch 18, Step 300] Loss: 4.7528, Acc: 0.3895\n",
      "Epoch 18 Completed - Avg Loss: 4.4737, Avg Acc: 0.3902\n",
      "[Epoch 19, Step 0] Loss: 4.2217, Acc: 0.3990\n",
      "[Epoch 19, Step 100] Loss: 4.3788, Acc: 0.3923\n",
      "[Epoch 19, Step 200] Loss: 4.6873, Acc: 0.3447\n",
      "[Epoch 19, Step 300] Loss: 4.3635, Acc: 0.4246\n",
      "Epoch 19 Completed - Avg Loss: 4.4323, Avg Acc: 0.3931\n",
      "[Epoch 20, Step 0] Loss: 4.5120, Acc: 0.3731\n",
      "[Epoch 20, Step 100] Loss: 4.3803, Acc: 0.4043\n",
      "[Epoch 20, Step 200] Loss: 4.3525, Acc: 0.4045\n",
      "[Epoch 20, Step 300] Loss: 4.4511, Acc: 0.3978\n",
      "Epoch 20 Completed - Avg Loss: 4.3919, Avg Acc: 0.3963\n",
      "[Epoch 21, Step 0] Loss: 3.8813, Acc: 0.4635\n",
      "[Epoch 21, Step 100] Loss: 4.4623, Acc: 0.3763\n",
      "[Epoch 21, Step 200] Loss: 4.0914, Acc: 0.4053\n",
      "[Epoch 21, Step 300] Loss: 4.3471, Acc: 0.4084\n",
      "Epoch 21 Completed - Avg Loss: 4.3515, Avg Acc: 0.3995\n",
      "[Epoch 22, Step 0] Loss: 4.1067, Acc: 0.4192\n",
      "[Epoch 22, Step 100] Loss: 4.2705, Acc: 0.4101\n",
      "[Epoch 22, Step 200] Loss: 4.4280, Acc: 0.3774\n",
      "[Epoch 22, Step 300] Loss: 4.4425, Acc: 0.3960\n",
      "Epoch 22 Completed - Avg Loss: 4.3119, Avg Acc: 0.4021\n",
      "[Epoch 23, Step 0] Loss: 4.4752, Acc: 0.3767\n",
      "[Epoch 23, Step 100] Loss: 4.0900, Acc: 0.4318\n",
      "[Epoch 23, Step 200] Loss: 4.0756, Acc: 0.4286\n",
      "[Epoch 23, Step 300] Loss: 4.2708, Acc: 0.3968\n",
      "Epoch 23 Completed - Avg Loss: 4.2814, Avg Acc: 0.4050\n",
      "[Epoch 24, Step 0] Loss: 4.3012, Acc: 0.3906\n",
      "[Epoch 24, Step 100] Loss: 4.4773, Acc: 0.3538\n",
      "[Epoch 24, Step 200] Loss: 4.2784, Acc: 0.3988\n",
      "[Epoch 24, Step 300] Loss: 3.8714, Acc: 0.4413\n",
      "Epoch 24 Completed - Avg Loss: 4.2473, Avg Acc: 0.4072\n",
      "[Epoch 25, Step 0] Loss: 4.2224, Acc: 0.4114\n",
      "[Epoch 25, Step 100] Loss: 4.1933, Acc: 0.3822\n",
      "[Epoch 25, Step 200] Loss: 3.9895, Acc: 0.4402\n",
      "[Epoch 25, Step 300] Loss: 4.0595, Acc: 0.4253\n",
      "Epoch 25 Completed - Avg Loss: 4.2140, Avg Acc: 0.4107\n",
      "[Epoch 26, Step 0] Loss: 4.1021, Acc: 0.4032\n",
      "[Epoch 26, Step 100] Loss: 4.2369, Acc: 0.3942\n",
      "[Epoch 26, Step 200] Loss: 4.8749, Acc: 0.3279\n",
      "[Epoch 26, Step 300] Loss: 3.9914, Acc: 0.4309\n",
      "Epoch 26 Completed - Avg Loss: 4.1820, Avg Acc: 0.4130\n",
      "[Epoch 27, Step 0] Loss: 4.1911, Acc: 0.4229\n",
      "[Epoch 27, Step 100] Loss: 3.9739, Acc: 0.4518\n",
      "[Epoch 27, Step 200] Loss: 3.9481, Acc: 0.4162\n",
      "[Epoch 27, Step 300] Loss: 4.3525, Acc: 0.3821\n",
      "Epoch 27 Completed - Avg Loss: 4.1523, Avg Acc: 0.4170\n",
      "[Epoch 28, Step 0] Loss: 3.9908, Acc: 0.4105\n",
      "[Epoch 28, Step 100] Loss: 3.8633, Acc: 0.4737\n",
      "[Epoch 28, Step 200] Loss: 4.0369, Acc: 0.4138\n",
      "[Epoch 28, Step 300] Loss: 3.9954, Acc: 0.4202\n",
      "Epoch 28 Completed - Avg Loss: 4.1249, Avg Acc: 0.4182\n",
      "[Epoch 29, Step 0] Loss: 3.8302, Acc: 0.4649\n",
      "[Epoch 29, Step 100] Loss: 4.1938, Acc: 0.4070\n",
      "[Epoch 29, Step 200] Loss: 3.7945, Acc: 0.4574\n",
      "[Epoch 29, Step 300] Loss: 4.1086, Acc: 0.4249\n",
      "Epoch 29 Completed - Avg Loss: 4.0943, Avg Acc: 0.4213\n",
      "[Epoch 30, Step 0] Loss: 4.3258, Acc: 0.4062\n",
      "[Epoch 30, Step 100] Loss: 4.0549, Acc: 0.4330\n",
      "[Epoch 30, Step 200] Loss: 3.9423, Acc: 0.4457\n",
      "[Epoch 30, Step 300] Loss: 3.6323, Acc: 0.5029\n",
      "Epoch 30 Completed - Avg Loss: 4.0687, Avg Acc: 0.4247\n",
      "[Epoch 31, Step 0] Loss: 3.8393, Acc: 0.4346\n",
      "[Epoch 31, Step 100] Loss: 3.7383, Acc: 0.4944\n",
      "[Epoch 31, Step 200] Loss: 4.1230, Acc: 0.4094\n",
      "[Epoch 31, Step 300] Loss: 4.0655, Acc: 0.4518\n",
      "Epoch 31 Completed - Avg Loss: 4.0437, Avg Acc: 0.4265\n",
      "[Epoch 32, Step 0] Loss: 4.1686, Acc: 0.3979\n",
      "[Epoch 32, Step 100] Loss: 4.0106, Acc: 0.4157\n",
      "[Epoch 32, Step 200] Loss: 3.9014, Acc: 0.4527\n",
      "[Epoch 32, Step 300] Loss: 4.0361, Acc: 0.4000\n",
      "Epoch 32 Completed - Avg Loss: 4.0156, Avg Acc: 0.4299\n",
      "[Epoch 33, Step 0] Loss: 3.7203, Acc: 0.4809\n",
      "[Epoch 33, Step 100] Loss: 4.0642, Acc: 0.4365\n",
      "[Epoch 33, Step 200] Loss: 3.9712, Acc: 0.4451\n",
      "[Epoch 33, Step 300] Loss: 3.9980, Acc: 0.4218\n",
      "Epoch 33 Completed - Avg Loss: 3.9910, Avg Acc: 0.4314\n",
      "[Epoch 34, Step 0] Loss: 4.1088, Acc: 0.4041\n",
      "[Epoch 34, Step 100] Loss: 3.6692, Acc: 0.4529\n",
      "[Epoch 34, Step 200] Loss: 3.8917, Acc: 0.4566\n",
      "[Epoch 34, Step 300] Loss: 3.8762, Acc: 0.4415\n",
      "Epoch 34 Completed - Avg Loss: 3.9671, Avg Acc: 0.4341\n",
      "[Epoch 35, Step 0] Loss: 3.9227, Acc: 0.4271\n",
      "[Epoch 35, Step 100] Loss: 3.7013, Acc: 0.4716\n",
      "[Epoch 35, Step 200] Loss: 3.8333, Acc: 0.4236\n",
      "[Epoch 35, Step 300] Loss: 4.0287, Acc: 0.4348\n",
      "Epoch 35 Completed - Avg Loss: 3.9426, Avg Acc: 0.4361\n",
      "[Epoch 36, Step 0] Loss: 3.8598, Acc: 0.4688\n",
      "[Epoch 36, Step 100] Loss: 4.3557, Acc: 0.4061\n",
      "[Epoch 36, Step 200] Loss: 3.6182, Acc: 0.4485\n",
      "[Epoch 36, Step 300] Loss: 3.7993, Acc: 0.4545\n",
      "Epoch 36 Completed - Avg Loss: 3.9205, Avg Acc: 0.4390\n",
      "[Epoch 37, Step 0] Loss: 3.9830, Acc: 0.3942\n",
      "[Epoch 37, Step 100] Loss: 4.2319, Acc: 0.3788\n",
      "[Epoch 37, Step 200] Loss: 3.7977, Acc: 0.4586\n",
      "[Epoch 37, Step 300] Loss: 4.5366, Acc: 0.3438\n",
      "Epoch 37 Completed - Avg Loss: 3.8949, Avg Acc: 0.4419\n",
      "[Epoch 38, Step 0] Loss: 4.1247, Acc: 0.4150\n",
      "[Epoch 38, Step 100] Loss: 3.6120, Acc: 0.4560\n",
      "[Epoch 38, Step 200] Loss: 3.1250, Acc: 0.5385\n",
      "[Epoch 38, Step 300] Loss: 3.9450, Acc: 0.4271\n",
      "Epoch 38 Completed - Avg Loss: 3.8749, Avg Acc: 0.4431\n",
      "[Epoch 39, Step 0] Loss: 4.0112, Acc: 0.4000\n",
      "[Epoch 39, Step 100] Loss: 3.8916, Acc: 0.4583\n",
      "[Epoch 39, Step 200] Loss: 3.8438, Acc: 0.4462\n",
      "[Epoch 39, Step 300] Loss: 3.7448, Acc: 0.4737\n",
      "Epoch 39 Completed - Avg Loss: 3.8504, Avg Acc: 0.4454\n",
      "[Epoch 40, Step 0] Loss: 4.0978, Acc: 0.4278\n",
      "[Epoch 40, Step 100] Loss: 3.8480, Acc: 0.4533\n",
      "[Epoch 40, Step 200] Loss: 3.5590, Acc: 0.4783\n",
      "[Epoch 40, Step 300] Loss: 3.4497, Acc: 0.5000\n",
      "Epoch 40 Completed - Avg Loss: 3.8295, Avg Acc: 0.4476\n",
      "[Epoch 41, Step 0] Loss: 3.7662, Acc: 0.4535\n",
      "[Epoch 41, Step 100] Loss: 3.8166, Acc: 0.4489\n",
      "[Epoch 41, Step 200] Loss: 3.6349, Acc: 0.4554\n",
      "[Epoch 41, Step 300] Loss: 3.5081, Acc: 0.4670\n",
      "Epoch 41 Completed - Avg Loss: 3.8102, Avg Acc: 0.4502\n",
      "[Epoch 42, Step 0] Loss: 3.9793, Acc: 0.4070\n",
      "[Epoch 42, Step 100] Loss: 3.5778, Acc: 0.5110\n",
      "[Epoch 42, Step 200] Loss: 3.9839, Acc: 0.4286\n",
      "[Epoch 42, Step 300] Loss: 3.8204, Acc: 0.4208\n",
      "Epoch 42 Completed - Avg Loss: 3.7911, Avg Acc: 0.4526\n",
      "[Epoch 43, Step 0] Loss: 3.7986, Acc: 0.4600\n",
      "[Epoch 43, Step 100] Loss: 3.9998, Acc: 0.4341\n",
      "[Epoch 43, Step 200] Loss: 3.9966, Acc: 0.4516\n",
      "[Epoch 43, Step 300] Loss: 4.0734, Acc: 0.4140\n",
      "Epoch 43 Completed - Avg Loss: 3.7690, Avg Acc: 0.4554\n",
      "[Epoch 44, Step 0] Loss: 3.8753, Acc: 0.4185\n",
      "[Epoch 44, Step 100] Loss: 3.6336, Acc: 0.4863\n",
      "[Epoch 44, Step 200] Loss: 3.9156, Acc: 0.4450\n",
      "[Epoch 44, Step 300] Loss: 3.3440, Acc: 0.5380\n",
      "Epoch 44 Completed - Avg Loss: 3.7488, Avg Acc: 0.4572\n",
      "[Epoch 45, Step 0] Loss: 3.6645, Acc: 0.4821\n",
      "[Epoch 45, Step 100] Loss: 3.6803, Acc: 0.4646\n",
      "[Epoch 45, Step 200] Loss: 3.6358, Acc: 0.4467\n",
      "[Epoch 45, Step 300] Loss: 3.7079, Acc: 0.4751\n",
      "Epoch 45 Completed - Avg Loss: 3.7322, Avg Acc: 0.4583\n",
      "[Epoch 46, Step 0] Loss: 3.9483, Acc: 0.4656\n",
      "[Epoch 46, Step 100] Loss: 3.8282, Acc: 0.4335\n",
      "[Epoch 46, Step 200] Loss: 4.1140, Acc: 0.4044\n",
      "[Epoch 46, Step 300] Loss: 3.4907, Acc: 0.4809\n",
      "Epoch 46 Completed - Avg Loss: 3.7120, Avg Acc: 0.4612\n",
      "[Epoch 47, Step 0] Loss: 3.8145, Acc: 0.4780\n",
      "[Epoch 47, Step 100] Loss: 3.7440, Acc: 0.4865\n",
      "[Epoch 47, Step 200] Loss: 3.6904, Acc: 0.4583\n",
      "[Epoch 47, Step 300] Loss: 3.5729, Acc: 0.4675\n",
      "Epoch 47 Completed - Avg Loss: 3.6927, Avg Acc: 0.4631\n",
      "[Epoch 48, Step 0] Loss: 3.7500, Acc: 0.4692\n",
      "[Epoch 48, Step 100] Loss: 3.9214, Acc: 0.4455\n",
      "[Epoch 48, Step 200] Loss: 3.3937, Acc: 0.5080\n",
      "[Epoch 48, Step 300] Loss: 4.0781, Acc: 0.4491\n",
      "Epoch 48 Completed - Avg Loss: 3.6761, Avg Acc: 0.4667\n",
      "[Epoch 49, Step 0] Loss: 3.2314, Acc: 0.5511\n",
      "[Epoch 49, Step 100] Loss: 3.5631, Acc: 0.5110\n",
      "[Epoch 49, Step 200] Loss: 3.7511, Acc: 0.4550\n",
      "[Epoch 49, Step 300] Loss: 3.4961, Acc: 0.4974\n",
      "Epoch 49 Completed - Avg Loss: 3.6571, Avg Acc: 0.4674\n",
      "[Epoch 50, Step 0] Loss: 3.5690, Acc: 0.4776\n",
      "[Epoch 50, Step 100] Loss: 3.6587, Acc: 0.4653\n",
      "[Epoch 50, Step 200] Loss: 3.6540, Acc: 0.4857\n",
      "[Epoch 50, Step 300] Loss: 3.6065, Acc: 0.4848\n",
      "Epoch 50 Completed - Avg Loss: 3.6387, Avg Acc: 0.4697\n",
      "[Epoch 51, Step 0] Loss: 3.6487, Acc: 0.4811\n",
      "[Epoch 51, Step 100] Loss: 3.5302, Acc: 0.4839\n",
      "[Epoch 51, Step 200] Loss: 3.7898, Acc: 0.4564\n",
      "[Epoch 51, Step 300] Loss: 3.5439, Acc: 0.4734\n",
      "Epoch 51 Completed - Avg Loss: 3.6203, Avg Acc: 0.4732\n",
      "[Epoch 52, Step 0] Loss: 3.7902, Acc: 0.4455\n",
      "[Epoch 52, Step 100] Loss: 3.3372, Acc: 0.5000\n",
      "[Epoch 52, Step 200] Loss: 3.9054, Acc: 0.4508\n",
      "[Epoch 52, Step 300] Loss: 3.6884, Acc: 0.4604\n",
      "Epoch 52 Completed - Avg Loss: 3.6032, Avg Acc: 0.4738\n",
      "[Epoch 53, Step 0] Loss: 3.7115, Acc: 0.4586\n",
      "[Epoch 53, Step 100] Loss: 3.6020, Acc: 0.4844\n",
      "[Epoch 53, Step 200] Loss: 3.3352, Acc: 0.5225\n",
      "[Epoch 53, Step 300] Loss: 3.3318, Acc: 0.5082\n",
      "Epoch 53 Completed - Avg Loss: 3.5839, Avg Acc: 0.4749\n",
      "[Epoch 54, Step 0] Loss: 3.6703, Acc: 0.4545\n",
      "[Epoch 54, Step 100] Loss: 3.0312, Acc: 0.5731\n",
      "[Epoch 54, Step 200] Loss: 3.2455, Acc: 0.4734\n",
      "[Epoch 54, Step 300] Loss: 3.6875, Acc: 0.4866\n",
      "Epoch 54 Completed - Avg Loss: 3.5656, Avg Acc: 0.4779\n",
      "[Epoch 55, Step 0] Loss: 3.5916, Acc: 0.4921\n",
      "[Epoch 55, Step 100] Loss: 3.4093, Acc: 0.4615\n",
      "[Epoch 55, Step 200] Loss: 3.7985, Acc: 0.4485\n",
      "[Epoch 55, Step 300] Loss: 3.6550, Acc: 0.4586\n",
      "Epoch 55 Completed - Avg Loss: 3.5529, Avg Acc: 0.4804\n",
      "[Epoch 56, Step 0] Loss: 3.2587, Acc: 0.5191\n",
      "[Epoch 56, Step 100] Loss: 3.7318, Acc: 0.4286\n",
      "[Epoch 56, Step 200] Loss: 3.8328, Acc: 0.4211\n",
      "[Epoch 56, Step 300] Loss: 3.5892, Acc: 0.4946\n",
      "Epoch 56 Completed - Avg Loss: 3.5357, Avg Acc: 0.4815\n",
      "[Epoch 57, Step 0] Loss: 3.5102, Acc: 0.4899\n",
      "[Epoch 57, Step 100] Loss: 3.6613, Acc: 0.4426\n",
      "[Epoch 57, Step 200] Loss: 3.7692, Acc: 0.4536\n",
      "[Epoch 57, Step 300] Loss: 3.6634, Acc: 0.5025\n",
      "Epoch 57 Completed - Avg Loss: 3.5193, Avg Acc: 0.4849\n",
      "[Epoch 58, Step 0] Loss: 3.5378, Acc: 0.4747\n",
      "[Epoch 58, Step 100] Loss: 3.4259, Acc: 0.4865\n",
      "[Epoch 58, Step 200] Loss: 3.0048, Acc: 0.5439\n",
      "[Epoch 58, Step 300] Loss: 3.7335, Acc: 0.4719\n",
      "Epoch 58 Completed - Avg Loss: 3.5022, Avg Acc: 0.4853\n",
      "[Epoch 59, Step 0] Loss: 3.6398, Acc: 0.4860\n",
      "[Epoch 59, Step 100] Loss: 3.6700, Acc: 0.4577\n",
      "[Epoch 59, Step 200] Loss: 3.4167, Acc: 0.5143\n",
      "[Epoch 59, Step 300] Loss: 3.5797, Acc: 0.4891\n",
      "Epoch 59 Completed - Avg Loss: 3.4891, Avg Acc: 0.4890\n",
      "[Epoch 60, Step 0] Loss: 3.3794, Acc: 0.5051\n",
      "[Epoch 60, Step 100] Loss: 3.3934, Acc: 0.4880\n",
      "[Epoch 60, Step 200] Loss: 3.9236, Acc: 0.4263\n",
      "[Epoch 60, Step 300] Loss: 3.4476, Acc: 0.4862\n",
      "Epoch 60 Completed - Avg Loss: 3.4701, Avg Acc: 0.4898\n",
      "CPU times: total: 1h 11min 40s\n",
      "Wall time: 12min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=60,  # 원하는 에폭 수\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "07ed3a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(model, sentence, tokenizer, device='cuda'):\n",
    "    START_TOKEN = tokenizer.bos_id()\n",
    "    END_TOKEN = tokenizer.eos_id()\n",
    "    MAX_LENGTH = 40\n",
    "\n",
    "    # 전처리\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 인코더 입력: [START] + 인코딩 + [END]\n",
    "    # 레이블 토큰 제거!\n",
    "    enc_input_ids = [START_TOKEN] + tokenizer.encode(sentence) + [END_TOKEN]\n",
    "    enc_input = torch.tensor([enc_input_ids], dtype=torch.long, device=device)\n",
    "\n",
    "    dec_input = torch.tensor([[START_TOKEN]], dtype=torch.long, device=device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(MAX_LENGTH):\n",
    "            logits = model(enc_input, dec_input)\n",
    "            last_step_logits = logits[:, -1, :]\n",
    "            predicted_id = torch.argmax(last_step_logits, dim=-1)\n",
    "\n",
    "            if predicted_id.item() == END_TOKEN:\n",
    "                break\n",
    "\n",
    "            predicted_id = predicted_id.unsqueeze(0)\n",
    "            dec_input = torch.cat([dec_input, predicted_id], dim=1)\n",
    "\n",
    "    output_sequence = dec_input.squeeze(0).tolist()\n",
    "    return output_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "119aba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, sentence, tokenizer, device='cuda'):\n",
    "    # 디코더 인퍼런스 -> 예측된 토큰 시퀀스\n",
    "    output_seq = decoder_inference(model, sentence, tokenizer, device=device)\n",
    "\n",
    "    # 토크나이저로 디코딩 (패딩, START/END 토큰 등은 제외하거나 처리)\n",
    "    # 여기서는 단순히 tokenizer.decode() 직접 호출\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [token for token in output_seq if token < tokenizer.GetPieceSize()]\n",
    "    )\n",
    "\n",
    "    print(\"입력 :\", sentence)\n",
    "    print(\"출력 :\", predicted_sentence)\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "d2de00b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 가스불 키고 나온거 같아\n",
      "출력 : 많이 지쳤나봐요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'많이 지쳤나봐요 .'"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = '가스불 키고 나온거 같아'\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "cef938cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 슬퍼.\n",
      "출력 : 저도 같이 가요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저도 같이 가요 .'"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"나 슬퍼.\"\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "44cd5949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 헤어졌어\n",
      "출력 : 좋은 사람 만날 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 사람 만날 거예요 .'"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"헤어졌어\"\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "0ebebd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def query_to_llm(num, path, model, sp, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    num: 생성할 문장 개수\n",
    "    path: ChatbotData.csv 경로\n",
    "    model: 학습된 Transformer 모델\n",
    "    sp: SentencePiece tokenizer\n",
    "    \"\"\"\n",
    "    path = \"ChatbotData.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    sentences = []\n",
    "\n",
    "    # Q 컬럼에서 랜덤으로 num개 추출\n",
    "    sample_qs = random.sample(df[\"Q\"].tolist(), num)\n",
    "\n",
    "    for sentence in sample_qs:\n",
    "        sentence = str(sentence).strip()\n",
    "        sentence_generation(model, sentence, sp, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "52aa6aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 언제쯤 잊혀질런지,,\n",
      "출력 : 너무 자책하지 마세요 .\n",
      "입력 : 이제는 너를 보낼 시간이 가까이 오는구나.\n",
      "출력 : 이제 좀 더 많이 만나보세요 .\n",
      "입력 : 놀이공원 데이트 어때?\n",
      "출력 : 어떤 선택이든 좋은 사람 만날 수 있을 거예요 .\n",
      "입력 : 헤어진 여자친구를 돌아오게 하는 방법!\n",
      "출력 : 먼저 연락해보세요 .\n",
      "입력 : 먼지가 너무 많아\n",
      "출력 : 너무 자책하지 마세요 .\n",
      "입력 : 한약 먹기 싫어\n",
      "출력 : 좋은 생각이에요 .\n",
      "입력 : 짝남 생각할수록 정리 되는 듯.\n",
      "출력 : 잘 지내고 있을 거예요 .\n",
      "입력 : 친구네 집이 부자라 우리집에 초대를 못하겠어\n",
      "출력 : 좋은 생각이에요 .\n"
     ]
    }
   ],
   "source": [
    "query_to_llm(8, path, model, sp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jedi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
