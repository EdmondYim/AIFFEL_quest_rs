{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f311eb",
   "metadata": {},
   "source": [
    "**Encoder 제거 + cross-attention 제거 + 전층 masked multi-head self-attention + 학습형 포지션 임베딩 + LM head(weight tying) + 입력을 태스크별로 직렬화 **\n",
    "\n",
    "\n",
    "## 1️. 전체 구조 (Encoder–Decoder → Decoder-Only)\n",
    "| 항목 | Transformer           | GPT-1 변경점                   |\n",
    "| -- | --------------------- | --------------------------- |\n",
    "| 구성 | Encoder + Decoder     | **Encoder 제거**, Decoder만 사용 |\n",
    "| 목적 | 번역(입력→출력)             | **언어모델링 (다음 단어 예측)**        |\n",
    "| 입력 | (source, target) 두 문장 | **단일 시퀀스** (문맥+토큰 스트림)      |\n",
    "\n",
    "## 2️. Self-Attention 블록\n",
    "| 항목              | Transformer                                  | GPT-1 변경점                             |\n",
    "| --------------- | -------------------------------------------- | ------------------------------------- |\n",
    "| 어텐션 방향          | Encoder는 양방향, Decoder는 masked | **모든 블록에서 masked self-attention만 사용** |\n",
    "| Cross-Attention | Decoder 내부에 Encoder 출력 참조용 존재                | **완전히 제거**                            |\n",
    "| Mask 종류         | look-ahead mask + encoder–decoder mask       | **masked multi-head self-attention만 유지**         |\n",
    "\n",
    "## 3️. 포지셔널 인코딩 (Positional Encoding)\n",
    "| 항목    | Transformer   | GPT-1 변경점                            |\n",
    "| ----- | ------------- | ------------------------------------ |\n",
    "| 방식    | 고정형 사인/코사인 함수 | **학습형 position embedding (learned)** |\n",
    "| 적용 시점 | 입력 임베딩에 더함    | 동일하게 더하지만, 파라미터 학습 가능                |\n",
    "\n",
    "## 4️. 입력 임베딩 (Token Embedding)\n",
    "| 항목     | Transformer      | GPT-1 변경점                                   |\n",
    "| ------ | ---------------- | ------------------------------------------- |\n",
    "| 입력 형태  | source/target 분리 | **단일 단어 시퀀스 입력**                            |\n",
    "| 가중치 공유 | 별도로 정의           | **입력 임베딩과 출력 Softmax 가중치 공유(weight tying)** |\n",
    "\n",
    "## 5️. Feed-Forward Network (FFN)\n",
    "| 항목    | Transformer             | GPT-1 변경점             |\n",
    "| ----- | ----------------------- | --------------------- |\n",
    "| 구조    | Linear → ReLU → Linear  | 동일 (GPT-1에서도 ReLU 유지) |\n",
    "| 적용 범위 | 각 위치 독립 (position-wise) | 동일                    |\n",
    "\n",
    "## 6️. Normalization 및 순서\n",
    "| 항목           | Transformer            | GPT-1 변경점                                |\n",
    "| ------------ | ---------------------- | ---------------------------------------- |\n",
    "| LayerNorm 위치 | Post-Norm (Residual 뒤) | **Pre-Norm 형태로 변경**  |\n",
    "| Residual 연결  | 동일하게 존재                | 동일하게 유지                                  |\n",
    "\n",
    "## 7️. 출력층 (Language Modeling Head)\n",
    "| 항목      | Transformer             | GPT-1 변경점                                       |\n",
    "| ------- | ----------------------- | ----------------------------------------------- |\n",
    "| 출력 대상   | 번역 단어 분포 (target vocab) | **다음 단어 확률 분포 **                            |\n",
    "| Softmax | decoder output → vocab  | **마지막 hidden → vocab softmax**, weight tying 사용 |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39742d39",
   "metadata": {},
   "source": [
    "## GPT 훈련 및 모델 설계 개요\n",
    "\n",
    "GPT를 훈련시킬 때는 디코더 훈련에서는 **순수 텍스트**를 입력으로 사용하며,  \n",
    "감정 토큰과 같은 추가 정보는 **마지막 선형 레이어를 미세 조정할 때** 투입하는 것이 일반적입니다.  \n",
    "\n",
    "그러나 이번 메인 퀘스트에서는 편의상, 논문 내 **_Question Answering and Commonsense Reasoning_** 형식인  \n",
    "`[z; q; $; a_k]` 구조를 모방하여 **처음부터 훈련 데이터에 포함하여 학습**했습니다.  \n",
    "\n",
    "검색과 논문을 통해 다음과 같은 구성에서  \n",
    "`Embedding(40, 768)` 중 **토큰 크기 40을 제외한 모든 부분을 직접 구현**하였습니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 모델 구조\n",
    "\n",
    "- **Decoder Layers:** 12개  \n",
    "- **Embedding / Hidden Size (d_model):** 768  \n",
    "- **Multi-Head Attention Heads:** 12개  \n",
    "- **Feed-Forward Network Size (d_ff):** 3072  \n",
    "- **활성화 함수:** GELU  \n",
    "- **포지셔널 인코딩:** 학습 가능한 Learned Positional Encoding 사용  \n",
    "\n",
    "---\n",
    "\n",
    "### 모델 조정 배경\n",
    "\n",
    "하드웨어 한계로 인해 여러 차례의 훈련 과정에서 **과적합(overfitting)** 이 관찰되었고,  \n",
    "이에 따라 **적당히 타협 가능한 수준으로 모델 설계를 변경**하였습니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 비교 및 검증\n",
    "\n",
    "첫 마크다운에서는  \n",
    "**GPT-1 논문**과 **Transformer 논문**을 비교하여  \n",
    "두 구조 간의 차이를 서술하여 **조건 1**을 만족하고,\n",
    "이어지는 단계에서는 **조건 2, 3, 4, 5**를 모두 만족함을 확인하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d019ffb9",
   "metadata": {},
   "source": [
    "## GPT-1 구조 비교\n",
    "![GPT-1 구조](pics/GPT_1.png)\n",
    "\n",
    "## 모델 학습 (model.fit)\n",
    "![모델 학습 과정](pics/model.fit().png)\n",
    "\n",
    "## 추론 결과 1 (Inference)\n",
    "![추론 결과](pics/inference_result.png)\n",
    "\n",
    "## 추론 결과 2 (Inference)\n",
    "![추론 결과](pics/inference_result_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe31ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import sentencepiece as spm\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c9c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.position = position\n",
    "\n",
    "        self.pos_encoding = self._build_pos_encoding(position, d_model)\n",
    "\n",
    "    def _get_angles(self, position, i, d_model):\n",
    "        return 1.0 / (10000.0 ** ((2.0 * (i // 2)) / d_model)) * position\n",
    "\n",
    "    def _build_pos_encoding(self, position, d_model):\n",
    "        pos = torch.arange(position, dtype=torch.float32).unsqueeze(1)\n",
    "        i = torch.arange(d_model, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        angle_rads = self._get_angles(pos, i, d_model)\n",
    "        sines = torch.sin(angle_rads[:, 0::2])\n",
    "        cosines = torch.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = torch.zeros(position, d_model)\n",
    "        pos_encoding[:, 0::2] = sines\n",
    "        pos_encoding[:, 1::2] = cosines\n",
    "\n",
    "        pos_encoding = pos_encoding.unsqueeze(0)  # shape: [1, position, d_model]\n",
    "        return pos_encoding\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pos_encoding[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "\n",
    "_get_angles, _build_pos_encoding 메서드 삭제\n",
    "nn.Embedding(max_position, d_model) 사용\n",
    "forward 시점에 실제 시퀀스 길이만큼의 위치 인덱스 생성\n",
    "\n",
    "'''\n",
    "max_seq_length = 40\n",
    "\n",
    "class LearnedPositionalEncoding(nn.Module):\n",
    "    def __init__(self, max_position, d_model):\n",
    "        super(LearnedPositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_position = max_position\n",
    "        \n",
    "        # 학습 가능한 positional embedding 파라미터\n",
    "        self.pos_embedding = nn.Embedding(max_position, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # 위치 인덱스 생성 [0, 1, 2, ..., seq_len-1]\n",
    "        positions = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, -1)\n",
    "        \n",
    "        # Embedding lookup을 통해 학습된 positional encoding 가져오기\n",
    "        pos_encodings = self.pos_embedding(positions)\n",
    "        \n",
    "        # 입력에 positional encoding 더하기\n",
    "        return x + pos_encodings\n",
    "\n",
    "\n",
    "# 데이터에 위치정보를 추가하는 클래스입니다.\n",
    "# Decoder 클래스에서 위치정보를 추가 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf3ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "\n",
    "    # 1) Q와 K의 내적을 통해 score(유사도) 계산\n",
    "    # key.transpose(-1, -2): (batch_size, heads, depth, seq_len)\n",
    "    # matmul 결과 shape: (batch_size, heads, seq_len, seq_len)\n",
    "    matmul_qk = torch.matmul(query, key.transpose(-1, -2))\n",
    "\n",
    "    # 2) depth에 따라 정규화\n",
    "    depth = key.size(-1)  # depth = d_model / heads\n",
    "    logits = matmul_qk / math.sqrt(depth)\n",
    "\n",
    "    # 3) 마스크가 주어졌다면 -1e9(아주 작은 값)를 더해 소프트맥스에서 제외시키도록 함\n",
    "    if mask is not None:\n",
    "        # 텐서플로우: logits += (mask * -1e9)\n",
    "        # 파이토치 동일 적용\n",
    "        logits = logits + (mask * -1e9)\n",
    "\n",
    "    # 4) 소프트맥스 계산해 attention weights 생성\n",
    "    attention_weights = F.softmax(logits, dim=-1)\n",
    "\n",
    "    # 5) attention weights와 value의 내적\n",
    "    output = torch.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights\n",
    "'''\n",
    "\n",
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    # query, key, value: (B, H, T, D), (B, H, S, D), (B, H, S, D)\n",
    "    # 1) 점수\n",
    "    logits = torch.matmul(query, key.transpose(-1, -2))  # (B, H, T, S)\n",
    "\n",
    "    # 2) 스케일링\n",
    "    depth = key.size(-1)\n",
    "    logits = logits / math.sqrt(depth)\n",
    "\n",
    "    # 3) 마스킹\n",
    "    if mask is not None:\n",
    "        # mask shape: (B, 1, T, S) or (B, H, T, S) → True/1이면 차단\n",
    "        logits = logits.masked_fill(mask.to(dtype=torch.bool), float(\"-inf\"))\n",
    "\n",
    "    # 4) 소프트맥스\n",
    "    attention_weights = F.softmax(logits, dim=-1)  # (B, H, T, S)\n",
    "\n",
    "    # 5) 가중합\n",
    "    output = torch.matmul(attention_weights, value)  # (B, H, T, D)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef3a883f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\nclass MultiHeadAttention(nn.Module):\\n    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\\n        super(MultiHeadAttention, self).__init__()\\n        self.num_heads = num_heads\\n        self.d_model = d_model\\n\\n        # d_model은 num_heads로 나누어떨어져야 함\\n        assert d_model % num_heads == 0\\n\\n        self.depth = d_model // num_heads\\n\\n        # 파이토치에서 Dense는 nn.Linear로 대응\\n        self.query_dense = nn.Linear(d_model, d_model)\\n        self.key_dense = nn.Linear(d_model, d_model)\\n        self.value_dense = nn.Linear(d_model, d_model)\\n\\n        self.out_dense = nn.Linear(d_model, d_model)\\n\\n    def split_heads(self, x, batch_size):\\n        \"\"\"\\n        x: (batch_size, seq_len, d_model)\\n        => (batch_size, num_heads, seq_len, depth) 형태로 변환\\n        \"\"\"\\n        x = x.view(batch_size, -1, self.num_heads, self.depth)\\n        x = x.permute(0, 2, 1, 3)  # (batch_size, num_heads, seq_len, depth)\\n        return x\\n\\n    def forward(self, query, key, value, mask=None):\\n        \"\"\"\\n        query, key, value: (batch_size, seq_len, d_model)\\n        mask: (batch_size, 1, seq_len, seq_len) 등으로 broadcast 가능하도록 구성\\n        \"\"\"\\n        batch_size = query.size(0)\\n\\n        # Q, K, V에 각각 Linear 적용\\n        query = self.query_dense(query)\\n        key = self.key_dense(key)\\n        value = self.value_dense(value)\\n\\n        # Head 분할\\n        query = self.split_heads(query, batch_size)\\n        key = self.split_heads(key, batch_size)\\n        value = self.split_heads(value, batch_size)\\n\\n        # 스케일드 닷 프로덕트 어텐션\\n        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\\n\\n        # (batch_size, num_heads, seq_len, depth) -> (batch_size, seq_len, num_heads, depth)\\n        scaled_attention = scaled_attention.permute(0, 2, 1, 3).contiguous()\\n\\n        # 다시 (batch_size, seq_len, d_model)로 합치기\\n        concat_attention = scaled_attention.view(batch_size, -1, self.d_model)\\n\\n        # 최종 Dense\\n        output = self.out_dense(concat_attention)\\n        return output\\n\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % num_heads == 0\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        self.query_dense = nn.Linear(d_model, d_model)\n",
    "        self.key_dense   = nn.Linear(d_model, d_model)\n",
    "        self.value_dense = nn.Linear(d_model, d_model)\n",
    "        self.out_dense   = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        # (B, L, D) -> (B, H, L, D/H)\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        return x\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        # query/key/value: (B, Lq/Dq), (B, Lk/Dk), (B, Lk/Dk) with D=d_model\n",
    "        B = query.size(0)\n",
    "\n",
    "        Q = self.query_dense(query)\n",
    "        K = self.key_dense(key)\n",
    "        V = self.value_dense(value)\n",
    "\n",
    "        Q = self.split_heads(Q, B)  # (B,H,T,Dh)\n",
    "        K = self.split_heads(K, B)  # (B,H,S,Dh)\n",
    "        V = self.split_heads(V, B)  # (B,H,S,Dh)\n",
    "\n",
    "        # mask: (B,1,T,S) or (B,H,T,S)\n",
    "        out, _ = scaled_dot_product_attention(Q, K, V, mask=mask)\n",
    "\n",
    "        # (B,H,T,Dh) -> (B,T,H,Dh) -> (B,T,D)\n",
    "        out = out.permute(0, 2, 1, 3).contiguous()\n",
    "        out = out.view(B, -1, self.d_model)\n",
    "        return self.out_dense(out)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # d_model은 num_heads로 나누어떨어져야 함\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        # 파이토치에서 Dense는 nn.Linear로 대응\n",
    "        self.query_dense = nn.Linear(d_model, d_model)\n",
    "        self.key_dense = nn.Linear(d_model, d_model)\n",
    "        self.value_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.out_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, d_model)\n",
    "        => (batch_size, num_heads, seq_len, depth) 형태로 변환\n",
    "        \"\"\"\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
    "        x = x.permute(0, 2, 1, 3)  # (batch_size, num_heads, seq_len, depth)\n",
    "        return x\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "        query, key, value: (batch_size, seq_len, d_model)\n",
    "        mask: (batch_size, 1, seq_len, seq_len) 등으로 broadcast 가능하도록 구성\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # Q, K, V에 각각 Linear 적용\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # Head 분할\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, depth) -> (batch_size, seq_len, num_heads, depth)\n",
    "        scaled_attention = scaled_attention.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "        # 다시 (batch_size, seq_len, d_model)로 합치기\n",
    "        concat_attention = scaled_attention.view(batch_size, -1, self.d_model)\n",
    "\n",
    "        # 최종 Dense\n",
    "        output = self.out_dense(concat_attention)\n",
    "        return output\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0703229",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)  # 이전에 구현한 MHA\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 피드포워드 부분 (Dense -> ReLU -> Dense)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, d_model)\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # (1) 멀티 헤드 어텐션 (셀프 어텐션)\n",
    "        attn_output = self.mha(x, x, x, mask)  # (batch_size, seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.norm1(x + attn_output)     # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # (2) 피드포워드 신경망\n",
    "        ffn_output = self.ffn(out1)            # (batch_size, seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.norm2(out1 + ffn_output)   # 잔차 연결 + LayerNorm\n",
    "\n",
    "        return out2\n",
    "\n",
    "인코더 레이어 불필요.\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a33ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 ff_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # (1) 임베딩 레이어\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩\n",
    "        \n",
    "        #self.pos_encoding = PositionalEncoding(position=vocab_size, d_model=d_model)\n",
    "        self.pos_encoding = PositionalEncoding(position=max_seq_length, d_model=d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # (3) EncoderLayer 쌓기\n",
    "        self.enc_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # (1) 임베딩 & sqrt(d_model)로 스케일링\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩 적용 + 드롭아웃\n",
    "        x = self.pos_encoding(x)  # shape: (batch_size, seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # (3) num_layers만큼 쌓아올린 EncoderLayer 통과\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        return x\n",
    "    \n",
    "인코더 불필요.\n",
    "\n",
    "'''\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83aadab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        # 첫 번째 서브 레이어 (디코더 내부 셀프 어텐션)\n",
    "        self.self_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 두 번째 서브 레이어 (인코더-디코더 어텐션)\n",
    "        #self.encdec_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        #self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        # cross-attention 은 불필요\n",
    "\n",
    "        # 세 번째 서브 레이어 (피드포워드 네트워크)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),  # Dense(units=ff_dim)\n",
    "            nn.GELU(),                   # activation='GELU' \n",
    "            nn.Linear(ff_dim, d_model)   # Dense(units=d_model)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 드롭아웃\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, look_ahead_mask=None):\n",
    "        # 1) 셀프 어텐션 (디코더 내부)\n",
    "        self_attn_out = self.self_mha(x, x, x, mask=look_ahead_mask)\n",
    "        self_attn_out = self.dropout1(self_attn_out)\n",
    "        out1 = self.norm1(x + self_attn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # 2) 인코더-디코더 어텐션\n",
    "        #encdec_attn_out = self.encdec_mha(out1, enc_outputs, enc_outputs, mask=padding_mask)\n",
    "        #encdec_attn_out = self.dropout2(encdec_attn_out)\n",
    "        #out2 = self.norm2(out1 + encdec_attn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # 3) 피드포워드 (Dense -> GELU -> Dense)\n",
    "        ffn_out = self.ffn(out1)\n",
    "        ffn_out = self.dropout2(ffn_out)\n",
    "        out2 = self.norm2(out1 + ffn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        return out2\n",
    "\n",
    "'''\n",
    "def create_padding_mask(x):\n",
    "    # x == 0 위치를 찾아 float형 1로 변환\n",
    "    mask = (x == 0).float()\n",
    "    # (batch_size, seq_len) -> (batch_size, 1, 1, seq_len)\n",
    "    mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "    return mask\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = x.size(1)\n",
    "\n",
    "    # (seq_len, seq_len) 크기의 하삼각 행렬(tril) 생성 후 1에서 빼서\n",
    "    # 상삼각이 1, 하삼각(자기 자신 포함)이 0이 되도록 설정\n",
    "    # => 미래 토큰(자신 인덱스보다 큰 위치) 마스킹\n",
    "    look_ahead_mask = 1 - torch.tril(torch.ones((seq_len, seq_len)))\n",
    "\n",
    "    # 패딩 마스크 생성 (shape: (batch_size, 1, 1, seq_len))\n",
    "    padding_mask = create_padding_mask(x)\n",
    "\n",
    "    # look_ahead_mask: (seq_len, seq_len) -> (1, seq_len, seq_len)\n",
    "    look_ahead_mask = look_ahead_mask.unsqueeze(0)\n",
    "    # -> (1, seq_len, seq_len) -> (1, 1, seq_len, seq_len)\n",
    "    look_ahead_mask = look_ahead_mask.unsqueeze(1)\n",
    "    look_ahead_mask = look_ahead_mask.to(x.device)\n",
    "\n",
    "    # look-ahead 마스크와 패딩 마스크를 합성 (둘 중 하나라도 1이면 마스킹)\n",
    "    # 최종 shape은 브로드캐스팅으로 (batch_size, 1, seq_len, seq_len)\n",
    "    combined_mask = torch.max(look_ahead_mask, padding_mask)\n",
    "    return combined_mask\n",
    "\n",
    "'''\n",
    "\n",
    "def create_padding_mask(x, pad_id: int = 0):\n",
    "    # x: (B, S)  키/밸류 시퀀스 길이에 맞춘 입력\n",
    "    mask = (x == pad_id).unsqueeze(1).unsqueeze(1).float()  # (B,1,1,S)\n",
    "    return mask\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "    # x: (B, T)  쿼리 시퀀스 길이에 맞춘 입력\n",
    "    B, T = x.size()\n",
    "    # 상삼각(미래) = 1, 나머지 = 0\n",
    "    la = torch.triu(torch.ones((T, T), device=x.device), diagonal=1)  # (T,T)\n",
    "    la = la.unsqueeze(0).unsqueeze(1).float()  # (1,1,T,T)\n",
    "    return la\n",
    "\n",
    "\n",
    "# 기존 코드와 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf3e9d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 ff_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dropout=0.1,\n",
    "                 max_seq_length=max_seq_length\n",
    "                 ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # (1) 임베딩 레이어\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩\n",
    "        # vocab_size에 맞추지않고 최대 시퀀스 길이\n",
    "        #self.pos_encoding = PositionalEncoding(position=vocab_size, d_model=d_model)\n",
    "        self.pos_encoding = LearnedPositionalEncoding(max_position=max_seq_length, d_model=d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # (3) DecoderLayer 쌓기\n",
    "        self.dec_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        #LayerNorm + LM head 추가\n",
    "        self.lm_head = nn.Linear(d_model, vocab_size, bias=False)\n",
    "        self.lm_head.weight = self.embedding.weight  # weight tying\n",
    "\n",
    "    def forward(self, x, look_ahead_mask=None, padding_mask=None):\n",
    "        # (1) 임베딩 + sqrt(d_model)로 스케일링\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩 + 드롭아웃\n",
    "        x = self.pos_encoding(x)    # (batch_size, tgt_seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # (3) num_layers만큼 쌓인 DecoderLayer 통과\n",
    "        for layer in self.dec_layers:\n",
    "            x = layer(x,look_ahead_mask) # enc_outputs, padding_mask 제거\n",
    "        logits = self.lm_head(x) \n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f63da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class GPT_1(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,      # num_layers = 12로 fix\n",
    "                 units,           # feed-forward 네트워크의 중간 차원(ff_dim)\n",
    "                 d_model,         # 임베딩 및 내부 표현 차원\n",
    "                 num_heads,       # 멀티헤드 어텐션의 헤드 수\n",
    "                 dropout=0.1):\n",
    "        super(GPT_1, self).__init__()\n",
    "\n",
    "        # 인코더 불필요\n",
    "        #self.encoder = Encoder(\n",
    "            #vocab_size=vocab_size,\n",
    "            #num_layers=num_layers,\n",
    "            #ff_dim=units,\n",
    "            #d_model=d_model,\n",
    "            #num_heads=num_heads,\n",
    "            #dropout=dropout\n",
    "        #)\n",
    "\n",
    "        # 디코더\n",
    "        self.decoder = Decoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # 최종 출력층: (d_model) -> (vocab_size)\n",
    "        self.final_linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        # 참고: 텐서플로우 코드의 `name=\"transformer\"`는 파이토치에선 보통 사용 안 함\n",
    "\n",
    "    def forward(self, inputs, dec_inputs):\n",
    "        # 1) 인코더 패딩 마스크 생성 제거\n",
    "        # enc_padding_mask = create_padding_mask(inputs)     # shape (batch_size, 1, 1, src_seq_len)\n",
    "\n",
    "        # 2) 디코더 look-ahead + 패딩 마스크\n",
    "        look_ahead_mask = create_look_ahead_mask(dec_inputs)  # shape (batch_size, 1, tgt_seq_len, tgt_seq_len)\n",
    "\n",
    "        # 3) 디코더에서 인코더 출력 쪽을 마스킹할 때 쓸 패딩 마스크\n",
    "        # dec_padding_mask = create_padding_mask(inputs)        # shape (batch_size, 1, 1, src_seq_len)\n",
    "\n",
    "        # 4) 인코더 수행\n",
    "        enc_outputs = self.encoder(\n",
    "            x=inputs,\n",
    "            mask=enc_padding_mask\n",
    "        )  # shape: (batch_size, src_seq_len, d_model)\n",
    "\n",
    "        # 5) 디코더 수행\n",
    "        dec_outputs = self.decoder(\n",
    "            x=dec_inputs,           # (batch_size, tgt_seq_len)\n",
    "            enc_outputs=enc_outputs,# (batch_size, src_seq_len, d_model)\n",
    "            look_ahead_mask=look_ahead_mask,\n",
    "            padding_mask=dec_padding_mask\n",
    "        )  # shape: (batch_size, tgt_seq_len, d_model)\n",
    "\n",
    "        # 6) 최종 Dense (vocab_size)\n",
    "        logits = self.final_linear(dec_outputs)  # (batch_size, tgt_seq_len, vocab_size)\n",
    "        return logits\n",
    "'''\n",
    "class GPT_1(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,      # num_layers = 12로 fix\n",
    "                 units,           # feed-forward 네트워크의 중간 차원(ff_dim)\n",
    "                 d_model,         # 임베딩 및 내부 표현 차원\n",
    "                 num_heads,       # 멀티헤드 어텐션의 헤드 수\n",
    "                 dropout=0.1,\n",
    "                 ):\n",
    "        super(GPT_1, self).__init__()\n",
    "\n",
    "        # 인코더 불필요 \n",
    "        # self.encoder = Encoder(\n",
    "        #     vocab_size=vocab_size,\n",
    "        #     num_layers=num_layers,\n",
    "        #     ff_dim=units,\n",
    "        #     d_model=d_model,\n",
    "        #     num_heads=num_heads,\n",
    "        #     dropout=dropout\n",
    "        # )\n",
    "\n",
    "        # 디코더 \n",
    "        self.decoder = Decoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            max_seq_length=max_seq_length\n",
    "        )\n",
    "\n",
    "        # 디코더가 hidden을 반환한다면 사용\n",
    "        # 디코더에서 정의했기 때문에 주석처리\n",
    "        # self.final_linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, dec_inputs):\n",
    "        # 인코더 마스크/출력 불필요\n",
    "        # enc_padding_mask = create_padding_mask(inputs)\n",
    "        # dec_padding_mask = create_padding_mask(inputs)\n",
    "\n",
    "        # look-ahead + padding 결합 마스크 (디코더 입력 기준)\n",
    "        look_ahead_mask = create_look_ahead_mask(dec_inputs)  # (B,1,T,T)\n",
    "\n",
    "        # 디코더 수행\n",
    "        # enc_outputs=None, padding_mask=None (cross-attn 제거)\n",
    "        dec_outputs = self.decoder(\n",
    "            x=dec_inputs,                 # (B, T)\n",
    "            #enc_outputs=None,             # 사용 안 함\n",
    "            look_ahead_mask=look_ahead_mask,\n",
    "            padding_mask=None\n",
    "        )  # 디코더가 hidden 또는 logits을 반환\n",
    "\n",
    "        # 1) 디코더가 hidden을 반환하는 경우 (기존 코드 유지)\n",
    "        #logits = self.final_linear(dec_outputs)\n",
    "\n",
    "        # 2) 디코더가 이미 logits을 반환하도록 구현.\n",
    "        logits = dec_outputs\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "507aaaf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT_1(\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(16000, 512)\n",
      "    (pos_encoding): LearnedPositionalEncoding(\n",
      "      (pos_embedding): Embedding(40, 512)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (dec_layers): ModuleList(\n",
      "      (0-11): 12 x DecoderLayer(\n",
      "        (self_mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (key_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (value_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (lm_head): Linear(in_features=512, out_features=16000, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 예: 하이퍼파라미터 설정\n",
    "NUM_LAYERS = 12     # 디코더 층 수\n",
    "D_MODEL = 512      # 임베딩 및 내부 표현 차원\n",
    "NUM_HEADS = 8      # 멀티헤드 어텐션에서의 헤드 수\n",
    "UNITS = 2048      # 피드포워드 신경망의 은닉 차원\n",
    "DROPOUT = 0.1      # 드롭아웃 비율\n",
    "VOCAB_SIZE = 16000 # 단어 집합 크기(예시)\n",
    "'''\n",
    "검색과 논문을 통해서 Embedding(40, 768)에서 토큰 크기 40을 제외한 모든 부분을 구현.\n",
    "\n",
    "Decoder Layers: 12개\n",
    "Embedding/Hidden Size (d_model): 768\n",
    "Multi-Head Attention Heads: 12개\n",
    "Feed-Forward Network Size (d_ff): 3072\n",
    "활성화 함수: GELU\n",
    "학습 가능한 포지셔널 인코딩 사용\n",
    "\n",
    "'''\n",
    "# 모델 생성\n",
    "model = GPT_1(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d32b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 폴더 경로\n",
    "path = 'ChatbotData.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bee7646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    5290\n",
      "1    3570\n",
      "2    2963\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n라벨 마다 갯수 차이가 남\\n0번 레이블의 답변이 매끄럽지 않을까? 하는 생각이 듦\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ChatbotData.csv')\n",
    "\n",
    "# 레이블 분포 확인\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 5))\n",
    "df['label'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Label Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1, 2], ['common(0)', 'negetive(1)', 'positive(2)'], rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "라벨 마다 갯수 차이가 남\n",
    "0번 레이블의 답변이 매끄럽지 않을까? 하는 생각이 듦\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f513a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # 1. 유니코드 정규화\n",
    "    sentence = unicodedata.normalize(\"NFC\", sentence)\n",
    "\n",
    "    # 2. 문장부호 앞뒤에 공백 삽입\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
    "\n",
    "    # 3. 허용 문자만 유지 (한글, 자모, 영문, 숫자, 공백, 주요 문장부호)\n",
    "    sentence = re.sub(r\"[^가-힣ㄱ-ㅎㅏ-ㅣA-Za-z0-9?.!,~… ]\", \" \", sentence)\n",
    "\n",
    "    # 4. 감정 표현 반복 상한 (4개 이상 → 2개)\n",
    "    sentence = re.sub(r'(ㅋ)\\1{3,}', r'\\1\\1', sentence)\n",
    "    sentence = re.sub(r'(ㅎ)\\1{3,}', r'\\1\\1', sentence)\n",
    "    sentence = re.sub(r'(ㅠ)\\1{3,}', r'\\1\\1', sentence)\n",
    "    sentence = re.sub(r'(ㅜ)\\1{3,}', r'\\1\\1', sentence)\n",
    "\n",
    "    # 5. 공백 정리\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence).strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ece1f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chatbot_csv(path,preprocess_sentence):\n",
    "    \"\"\"\n",
    "    반환: [(Q_clean, A_clean, label), ...]\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    qs = df[\"Q\"].astype(str).map(preprocess_sentence)\n",
    "    as_ = df[\"A\"].astype(str).map(preprocess_sentence)\n",
    "    labels = df[\"label\"].astype(int)\n",
    "    return list(zip(qs, as_, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "487105d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_chatbot_csv(path, preprocess_sentence)\n",
    "\n",
    "def sanitize_keep_tags(s: str) -> str:\n",
    "    # 탭/캐리지리턴만 제거. <, >, $ 보존.\n",
    "    return s.replace(\"\\t\", \" \").replace(\"\\r\", \" \").strip()\n",
    "\n",
    "with open(\"clean_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for q, a, label in data:\n",
    "        if q and a:\n",
    "            q_ = sanitize_keep_tags(q)\n",
    "            a_ = sanitize_keep_tags(a)\n",
    "            # 단일 시퀀스: [q ; $ ; a]\n",
    "            text = f\"<user> {q_} $ <assistant> {a_}\" # [z;q;$;ak​]\n",
    "            f.write(f\"{label}\\t{text}\\n\")\n",
    "\n",
    "\n",
    "# 단일 시퀀스. 특수토큰은 SPM에서 처리\n",
    "# 논문 내 Question Answering and Commonsense Reasoning 형식 // [z;q;$;ak​]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76af4f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n감정 label이 존재하여, \\n\\nspm에서 label을 포함한 사용자 정의 토큰 정의\\n\\nlabel_token = self.label_map[label] 으로 \\n\\nspm 모델에 정의된 토큰 ID를 동적으로 가져오는 부분 추가\\n\\n>>> 감정 + Q 형태로 학습 진행됨을 확인\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.Train(\n",
    "    input='clean_corpus.txt',\n",
    "    model_prefix=\"chatbot_spm\",\n",
    "    vocab_size=16000,\n",
    "    character_coverage=0.9995,\n",
    "    model_type=\"bpe\",  # 한국어면 unigram도 가능\n",
    "    max_sentence_length=999999,\n",
    "\n",
    "    pad_id=0,   # <pad>\n",
    "    unk_id=1,   # <unk>\n",
    "    bos_id=2,   # <s>\n",
    "    eos_id=3,   # </s>\n",
    "\n",
    "    # 사용자 정의 토큰: 라벨 대신 역할 기반 /  라벨도\n",
    "    user_defined_symbols=[\n",
    "        \"<user>\", \"<assistant>\", \"<label_0>\", \"<label_1>\", \"<label_2>\", \"$\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "'''\n",
    "감정 label이 존재하여, \n",
    "\n",
    "spm에서 label을 포함한 사용자 정의 토큰 정의\n",
    "\n",
    "label_token = self.label_map[label] 으로 \n",
    "\n",
    "spm 모델에 정의된 토큰 ID를 동적으로 가져오는 부분 추가\n",
    "\n",
    ">>> 감정 + Q 형태로 학습 진행됨을 확인\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc77c764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"chatbot_spm.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95c1a511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 7 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n<pad>\\t0\\n<unk>\\t0\\n<s>\\t0\\n</s>\\t0\\n<user>\\t0\\n<assistant>\\t0\\n<label_0>\\t0\\n<label_1>\\t0\\n<label_2>\\t0\\n$\\t0\\n\\n전부 매핑 완료\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sp.piece_to_id(\"<label_0>\"), sp.piece_to_id(\"<label_1>\"), sp.piece_to_id(\"<label_2>\"))\n",
    "\n",
    "# label 0,1,2 가 토큰 4,5,6에 매핑됨을 확인\n",
    "\n",
    "\n",
    "'''\n",
    "<pad>\t0\n",
    "<unk>\t0\n",
    "<s>\t0\n",
    "</s>\t0\n",
    "<user>\t0\n",
    "<assistant>\t0\n",
    "<label_0>\t0\n",
    "<label_1>\t0\n",
    "<label_2>\t0\n",
    "$\t0\n",
    "\n",
    "전부 매핑 완료\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee975af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass ChatbotDataset(Dataset):\\n    def __init__(self, data, sp, max_length=40):\\n        self.sp = sp\\n        self.max_length = max_length\\n        self.data = []\\n\\n        # spm 모델에 정의된 토큰 ID를 동적으로 가져오기\\n        self.label_map = {\\n            0: self.sp.piece_to_id(\\'<label_0>\\'),\\n            1: self.sp.piece_to_id(\\'<label_1>\\'),\\n            2: self.sp.piece_to_id(\\'<label_2>\\')\\n        }\\n\\n\\n        for q, a, label in data:\\n            bos_id = self.sp.bos_id()\\n            eos_id = self.sp.eos_id()\\n            label_token = self.label_map[label]\\n\\n            q_ids = self.sp.encode_as_ids(q)\\n            a_ids = self.sp.encode_as_ids(a)\\n\\n            q_tokens = [bos_id] + [label_token] + q_ids + [eos_id] \\n            # 이전[[<label_k>][BOS] Q [EOS]]  >>> 변경[[BOS][<label_k>] Q [EOS]]\\n            # 얼마나 성능 향상이 있었나? \\n            a_tokens = [bos_id] + a_ids + [eos_id]\\n\\n            if len(q_tokens) > self.max_length or len(a_tokens) > self.max_length:\\n                continue\\n\\n            q_tokens += [self.sp.pad_id()] * (self.max_length - len(q_tokens))\\n            a_tokens += [self.sp.pad_id()] * (self.max_length - len(a_tokens))\\n\\n            dec_input = a_tokens[:-1]\\n            target = a_tokens[1:]\\n\\n            self.data.append({\\n                \"enc_input\": q_tokens,\\n                \"dec_input\": dec_input,\\n                \"target\": target\\n            })\\n\\n    def __len__(self):\\n        return len(self.data)\\n\\n    def __getitem__(self, idx):\\n        sample = self.data[idx]\\n        enc_input = torch.tensor(sample[\"enc_input\"], dtype=torch.long)\\n        dec_input = torch.tensor(sample[\"dec_input\"], dtype=torch.long)\\n        target = torch.tensor(sample[\"target\"], dtype=torch.long)\\n        return enc_input, dec_input, target\\n\\nq_tokens, a_tokens을 구분할 필요가 없기 때문에, Question Answering and Commonsense Reasoning\\n구조를 모방하여 입력\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self, data, sp, max_length=40):\n",
    "        self.sp = sp\n",
    "        self.max_length = max_length\n",
    "        self.data = []\n",
    "\n",
    "        # spm 모델에 정의된 토큰 ID를 동적으로 가져오기\n",
    "        self.label_map = {\n",
    "            0: self.sp.piece_to_id('<label_0>'),\n",
    "            1: self.sp.piece_to_id('<label_1>'),\n",
    "            2: self.sp.piece_to_id('<label_2>')\n",
    "        }\n",
    "\n",
    "        \n",
    "        for q, a, label in data:\n",
    "            bos_id = self.sp.bos_id()\n",
    "            eos_id = self.sp.eos_id()\n",
    "            label_token = self.label_map[label]\n",
    "\n",
    "            q_ids = self.sp.encode_as_ids(q)\n",
    "            a_ids = self.sp.encode_as_ids(a)\n",
    "\n",
    "            q_tokens = [bos_id] + [label_token] + q_ids + [eos_id] \n",
    "            # 이전[[<label_k>][BOS] Q [EOS]]  >>> 변경[[BOS][<label_k>] Q [EOS]]\n",
    "            # 얼마나 성능 향상이 있었나? \n",
    "            a_tokens = [bos_id] + a_ids + [eos_id]\n",
    "\n",
    "            if len(q_tokens) > self.max_length or len(a_tokens) > self.max_length:\n",
    "                continue\n",
    "\n",
    "            q_tokens += [self.sp.pad_id()] * (self.max_length - len(q_tokens))\n",
    "            a_tokens += [self.sp.pad_id()] * (self.max_length - len(a_tokens))\n",
    "\n",
    "            dec_input = a_tokens[:-1]\n",
    "            target = a_tokens[1:]\n",
    "\n",
    "            self.data.append({\n",
    "                \"enc_input\": q_tokens,\n",
    "                \"dec_input\": dec_input,\n",
    "                \"target\": target\n",
    "            })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        enc_input = torch.tensor(sample[\"enc_input\"], dtype=torch.long)\n",
    "        dec_input = torch.tensor(sample[\"dec_input\"], dtype=torch.long)\n",
    "        target = torch.tensor(sample[\"target\"], dtype=torch.long)\n",
    "        return enc_input, dec_input, target\n",
    "\n",
    "q_tokens, a_tokens을 구분할 필요가 없기 때문에, Question Answering and Commonsense Reasoning\n",
    "구조를 모방하여 입력\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73e41803",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self, data, sp, max_length=80):\n",
    "        self.sp = sp\n",
    "        self.max_length = max_length\n",
    "        self.data = []\n",
    "\n",
    "        # 라벨 토큰 ID\n",
    "        self.label_map = {\n",
    "            0: self.sp.piece_to_id(\"<label_0>\"),\n",
    "            1: self.sp.piece_to_id(\"<label_1>\"),\n",
    "            2: self.sp.piece_to_id(\"<label_2>\")\n",
    "        }\n",
    "\n",
    "        bos_id = self.sp.bos_id()\n",
    "        eos_id = self.sp.eos_id()\n",
    "        pad_id = self.sp.pad_id()\n",
    "        dollar_id = self.sp.piece_to_id(\"$\") # dollar_id 변수는 불필요하나, 나중에 토큰 검사하려고 넣어둠\n",
    "\n",
    "        for q, a, label in data:\n",
    "            label_token = self.label_map[label]\n",
    "\n",
    "            # 입력: <label_k> <user> Q $ <assistant> A\n",
    "            seq = f\"<label_{label}> <user> {q} $ <assistant> {a}\"  #Question Answering and Commonsense Reasoning\n",
    "            ids = self.sp.encode_as_ids(seq)\n",
    "\n",
    "            # BOS/EOS 추가\n",
    "            tokens = [bos_id] + ids + [eos_id]\n",
    "\n",
    "            # 길이 제한\n",
    "            if len(tokens) > self.max_length:\n",
    "                tokens = tokens[:self.max_length]\n",
    "            else:\n",
    "                tokens += [pad_id] * (self.max_length - len(tokens))\n",
    "\n",
    "            # 다음 토큰 예측\n",
    "            input_ids = tokens[:-1]\n",
    "            target_ids = tokens[1:]\n",
    "\n",
    "            self.data.append({\n",
    "                \"input\": input_ids,\n",
    "                \"target\": target_ids\n",
    "            })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        input_ids = torch.tensor(sample[\"input\"], dtype=torch.long)\n",
    "        target_ids = torch.tensor(sample[\"target\"], dtype=torch.long)\n",
    "        return input_ids, target_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6146841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_chatbot_csv(path, preprocess_sentence)\n",
    "dataset = ChatbotDataset(data, sp, max_length=40)\n",
    "dataloader = DataLoader(dataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38786e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 39])\n",
      "torch.Size([64, 39])\n"
     ]
    }
   ],
   "source": [
    "for input_ids, target_ids in dataloader:\n",
    "    print(input_ids.size())   # [batch, seq_len]\n",
    "    print(target_ids.size())  # [batch, seq_len]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af03d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(ignore_index=sp.pad_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4eb312cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 수정된 학습률 함수\n",
    "'''\n",
    "def get_lr_lambda(d_model, warmup_steps=4000):\n",
    "    d_model = float(d_model)\n",
    "    def lr_lambda(step):\n",
    "        step = max(step, 1)  # 0으로 나누는 것 방지\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (warmup_steps ** -1.5)\n",
    "        return (d_model ** -0.5) * min(arg1, arg2) * 10  # 스케일 증가\n",
    "    return lr_lambda\n",
    "\n",
    "    수렴속도가 느림. \n",
    "'''\n",
    "def get_lr_lambda(d_model, warmup_steps=2000):\n",
    "    d_model = float(d_model)\n",
    "    def lr_lambda(step):\n",
    "        step = max(step, 1)\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (warmup_steps ** -1.5)\n",
    "        return (d_model ** -0.5) * min(arg1, arg2) * 10  # 15 ->10\n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57736254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "d_model = 512\n",
    "warmup_steps = 4000\n",
    "total_steps = 200000  # 총 학습 스텝\n",
    "\n",
    "# 학습률 스케줄 시각화\n",
    "steps = np.arange(1, total_steps + 1)\n",
    "learning_rates = [get_lr_lambda(d_model, warmup_steps)(step) for step in steps]\n",
    "\n",
    "# 그래프 출력\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, learning_rates, label=\"Learning Rate\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Transformer Learning Rate Schedule\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3201c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer 정의\n",
    "optimizer = optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-9) # 논문과 동일한 Adam\n",
    "\n",
    "# Scheduler 정의\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=get_lr_lambda(D_MODEL, warmup_steps=2000))\n",
    "\n",
    "def accuracy_function(y_pred, y_true, pad_id=0):\n",
    "    \"\"\"\n",
    "    y_pred: (batch_size, seq_len, vocab_size)\n",
    "    y_true: (batch_size, seq_len)\n",
    "    \"\"\"\n",
    "    preds = y_pred.argmax(dim=-1)  # (batch_size, seq_len)\n",
    "    mask = (y_true != pad_id)\n",
    "    correct = (preds == y_true) & mask\n",
    "    acc = correct.float().sum() / mask.float().sum()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "deb05173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68d90fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def train_step(model, batch, optimizer, loss_function, device):\n",
    "    model.train()\n",
    "    enc_input, dec_input, target = [x.to(device) for x in batch]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 모델 포워드 패스\n",
    "    logits = model(enc_input, dec_input)  # (batch_size, seq_len, vocab_size)\n",
    "\n",
    "    # Loss 계산 (패딩 토큰 무시)\n",
    "    loss = loss_function(logits.permute(0, 2, 1), target)  # (batch_size, vocab_size, seq_len) 필요\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), accuracy_function(logits, target, pad_id=sp.pad_id())\n",
    "\n",
    "'''\n",
    "def train_step(model, batch, optimizer, loss_function, device, pad_id):\n",
    "    model.train()\n",
    "\n",
    "    # (input_ids, target_ids)로 받음\n",
    "    input_ids, target_ids = [x.to(device) for x in batch]\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    # 포워드: 디코더 전용 LM은 입력 하나 / loss = loss_function(logits.permute(0, 2, 1) 안해도 무방\n",
    "    logits = model(input_ids)  # [B, T, V]\n",
    "\n",
    "    # CE는 [N,V] vs [N] 형태 기대\n",
    "    loss = loss_function(\n",
    "        logits.reshape(-1, logits.size(-1)),\n",
    "        target_ids.reshape(-1)\n",
    "    )\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), accuracy_function(logits, target_ids, pad_id=pad_id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69892077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_function, scheduler, num_epochs, device):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss, total_acc = 0, 0\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            # train_step 호출만 수정\n",
    "            loss, acc = train_step(\n",
    "                model, batch, optimizer, loss_function, device, pad_id=sp.pad_id()\n",
    "            )\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                print(f\"[Epoch {epoch+1}, Step {step}] Loss: {loss:.4f}, Acc: {acc:.4f}\")\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_acc = total_acc / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1} Completed - Avg Loss: {avg_loss:.4f}, Avg Acc: {avg_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c36bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Step 0] Loss: 283.8943, Acc: 0.0008\n",
      "[Epoch 1, Step 100] Loss: 235.7289, Acc: 0.0000\n",
      "Epoch 1 Completed - Avg Loss: 228.2419, Avg Acc: 0.0006\n",
      "[Epoch 2, Step 0] Loss: 122.8313, Acc: 0.0000\n",
      "[Epoch 2, Step 100] Loss: 55.0532, Acc: 0.0439\n",
      "Epoch 2 Completed - Avg Loss: 63.9011, Avg Acc: 0.0386\n",
      "[Epoch 3, Step 0] Loss: 36.9635, Acc: 0.0924\n",
      "[Epoch 3, Step 100] Loss: 30.0541, Acc: 0.1600\n",
      "Epoch 3 Completed - Avg Loss: 31.1663, Avg Acc: 0.1541\n",
      "[Epoch 4, Step 0] Loss: 27.2034, Acc: 0.2423\n",
      "[Epoch 4, Step 100] Loss: 24.5576, Acc: 0.3021\n",
      "Epoch 4 Completed - Avg Loss: 24.2719, Avg Acc: 0.2947\n",
      "[Epoch 5, Step 0] Loss: 22.6323, Acc: 0.3455\n",
      "[Epoch 5, Step 100] Loss: 20.4176, Acc: 0.3968\n",
      "Epoch 5 Completed - Avg Loss: 21.1499, Avg Acc: 0.3907\n",
      "[Epoch 6, Step 0] Loss: 18.9590, Acc: 0.4278\n",
      "[Epoch 6, Step 100] Loss: 19.0542, Acc: 0.4336\n",
      "Epoch 6 Completed - Avg Loss: 19.6883, Avg Acc: 0.4358\n",
      "[Epoch 7, Step 0] Loss: 18.3687, Acc: 0.4480\n",
      "[Epoch 7, Step 100] Loss: 19.2180, Acc: 0.4345\n",
      "Epoch 7 Completed - Avg Loss: 18.8187, Avg Acc: 0.4463\n",
      "[Epoch 8, Step 0] Loss: 18.6078, Acc: 0.4542\n",
      "[Epoch 8, Step 100] Loss: 17.4279, Acc: 0.4548\n",
      "Epoch 8 Completed - Avg Loss: 18.1788, Avg Acc: 0.4535\n",
      "[Epoch 9, Step 0] Loss: 17.6802, Acc: 0.4566\n",
      "[Epoch 9, Step 100] Loss: 18.2103, Acc: 0.4437\n",
      "Epoch 9 Completed - Avg Loss: 17.6482, Avg Acc: 0.4591\n",
      "[Epoch 10, Step 0] Loss: 17.3822, Acc: 0.4493\n",
      "[Epoch 10, Step 100] Loss: 17.1815, Acc: 0.4805\n",
      "Epoch 10 Completed - Avg Loss: 17.1569, Avg Acc: 0.4635\n",
      "[Epoch 11, Step 0] Loss: 17.7494, Acc: 0.4654\n",
      "[Epoch 11, Step 100] Loss: 17.1844, Acc: 0.4612\n",
      "Epoch 11 Completed - Avg Loss: 16.6838, Avg Acc: 0.4685\n",
      "[Epoch 12, Step 0] Loss: 15.9949, Acc: 0.4729\n",
      "[Epoch 12, Step 100] Loss: 17.0294, Acc: 0.4500\n",
      "Epoch 12 Completed - Avg Loss: 16.2362, Avg Acc: 0.4716\n",
      "[Epoch 13, Step 0] Loss: 15.5264, Acc: 0.4814\n",
      "[Epoch 13, Step 100] Loss: 16.4175, Acc: 0.4638\n",
      "Epoch 13 Completed - Avg Loss: 15.8382, Avg Acc: 0.4743\n",
      "[Epoch 14, Step 0] Loss: 15.6924, Acc: 0.4537\n",
      "[Epoch 14, Step 100] Loss: 15.5516, Acc: 0.4641\n",
      "Epoch 14 Completed - Avg Loss: 15.4759, Avg Acc: 0.4765\n",
      "[Epoch 15, Step 0] Loss: 15.4263, Acc: 0.4597\n",
      "[Epoch 15, Step 100] Loss: 15.6513, Acc: 0.4772\n",
      "Epoch 15 Completed - Avg Loss: 15.1434, Avg Acc: 0.4798\n",
      "[Epoch 16, Step 0] Loss: 15.8140, Acc: 0.4693\n",
      "[Epoch 16, Step 100] Loss: 14.7748, Acc: 0.4868\n",
      "Epoch 16 Completed - Avg Loss: 14.8436, Avg Acc: 0.4815\n",
      "[Epoch 17, Step 0] Loss: 14.7521, Acc: 0.4933\n",
      "[Epoch 17, Step 100] Loss: 15.6042, Acc: 0.4545\n",
      "Epoch 17 Completed - Avg Loss: 14.5599, Avg Acc: 0.4829\n",
      "[Epoch 18, Step 0] Loss: 15.0059, Acc: 0.4629\n",
      "[Epoch 18, Step 100] Loss: 15.2739, Acc: 0.4828\n",
      "Epoch 18 Completed - Avg Loss: 14.2908, Avg Acc: 0.4850\n",
      "[Epoch 19, Step 0] Loss: 14.0092, Acc: 0.4867\n",
      "[Epoch 19, Step 100] Loss: 14.5486, Acc: 0.4745\n",
      "Epoch 19 Completed - Avg Loss: 14.0397, Avg Acc: 0.4860\n",
      "[Epoch 20, Step 0] Loss: 13.6509, Acc: 0.4872\n",
      "[Epoch 20, Step 100] Loss: 13.5837, Acc: 0.5017\n",
      "Epoch 20 Completed - Avg Loss: 13.8105, Avg Acc: 0.4880\n",
      "[Epoch 21, Step 0] Loss: 14.0271, Acc: 0.4922\n",
      "[Epoch 21, Step 100] Loss: 13.8191, Acc: 0.5064\n",
      "Epoch 21 Completed - Avg Loss: 13.5888, Avg Acc: 0.4879\n",
      "[Epoch 22, Step 0] Loss: 13.5194, Acc: 0.4888\n",
      "[Epoch 22, Step 100] Loss: 13.2849, Acc: 0.4873\n",
      "Epoch 22 Completed - Avg Loss: 13.3761, Avg Acc: 0.4894\n",
      "[Epoch 23, Step 0] Loss: 13.5028, Acc: 0.4953\n",
      "[Epoch 23, Step 100] Loss: 13.0206, Acc: 0.4818\n",
      "Epoch 23 Completed - Avg Loss: 13.1732, Avg Acc: 0.4908\n",
      "[Epoch 24, Step 0] Loss: 13.8468, Acc: 0.4821\n",
      "[Epoch 24, Step 100] Loss: 12.1249, Acc: 0.4915\n",
      "Epoch 24 Completed - Avg Loss: 12.9775, Avg Acc: 0.4907\n",
      "[Epoch 25, Step 0] Loss: 11.6708, Acc: 0.5064\n",
      "[Epoch 25, Step 100] Loss: 12.5861, Acc: 0.4941\n",
      "Epoch 25 Completed - Avg Loss: 12.7928, Avg Acc: 0.4918\n",
      "[Epoch 26, Step 0] Loss: 13.7113, Acc: 0.4659\n",
      "[Epoch 26, Step 100] Loss: 12.2515, Acc: 0.5004\n",
      "Epoch 26 Completed - Avg Loss: 12.6128, Avg Acc: 0.4930\n",
      "[Epoch 27, Step 0] Loss: 12.8303, Acc: 0.4818\n",
      "[Epoch 27, Step 100] Loss: 12.2165, Acc: 0.5021\n",
      "Epoch 27 Completed - Avg Loss: 12.4378, Avg Acc: 0.4939\n",
      "[Epoch 28, Step 0] Loss: 12.0085, Acc: 0.4983\n",
      "[Epoch 28, Step 100] Loss: 11.7740, Acc: 0.4979\n",
      "Epoch 28 Completed - Avg Loss: 12.2754, Avg Acc: 0.4946\n",
      "[Epoch 29, Step 0] Loss: 12.0441, Acc: 0.5029\n",
      "[Epoch 29, Step 100] Loss: 12.1006, Acc: 0.5078\n",
      "Epoch 29 Completed - Avg Loss: 12.1160, Avg Acc: 0.4952\n",
      "[Epoch 30, Step 0] Loss: 11.6186, Acc: 0.5098\n",
      "[Epoch 30, Step 100] Loss: 12.0200, Acc: 0.5068\n",
      "Epoch 30 Completed - Avg Loss: 11.9575, Avg Acc: 0.4959\n",
      "[Epoch 31, Step 0] Loss: 12.2123, Acc: 0.4931\n",
      "[Epoch 31, Step 100] Loss: 12.5966, Acc: 0.5000\n",
      "Epoch 31 Completed - Avg Loss: 11.8093, Avg Acc: 0.4961\n",
      "[Epoch 32, Step 0] Loss: 11.2291, Acc: 0.4984\n",
      "[Epoch 32, Step 100] Loss: 11.4333, Acc: 0.4777\n",
      "Epoch 32 Completed - Avg Loss: 11.6605, Avg Acc: 0.4975\n",
      "[Epoch 33, Step 0] Loss: 11.3733, Acc: 0.5075\n",
      "[Epoch 33, Step 100] Loss: 10.8209, Acc: 0.4983\n",
      "Epoch 33 Completed - Avg Loss: 11.5216, Avg Acc: 0.4974\n",
      "[Epoch 34, Step 0] Loss: 11.9650, Acc: 0.4846\n",
      "[Epoch 34, Step 100] Loss: 11.7553, Acc: 0.4833\n",
      "Epoch 34 Completed - Avg Loss: 11.3930, Avg Acc: 0.4983\n",
      "[Epoch 35, Step 0] Loss: 12.1892, Acc: 0.4821\n",
      "[Epoch 35, Step 100] Loss: 11.0025, Acc: 0.5000\n",
      "Epoch 35 Completed - Avg Loss: 11.2619, Avg Acc: 0.4993\n",
      "[Epoch 36, Step 0] Loss: 12.1814, Acc: 0.5034\n",
      "[Epoch 36, Step 100] Loss: 11.3286, Acc: 0.4874\n",
      "Epoch 36 Completed - Avg Loss: 11.1338, Avg Acc: 0.4998\n",
      "[Epoch 37, Step 0] Loss: 11.4346, Acc: 0.5200\n",
      "[Epoch 37, Step 100] Loss: 11.5373, Acc: 0.5029\n",
      "Epoch 37 Completed - Avg Loss: 11.0128, Avg Acc: 0.5005\n",
      "[Epoch 38, Step 0] Loss: 11.3251, Acc: 0.4893\n",
      "[Epoch 38, Step 100] Loss: 11.2301, Acc: 0.4892\n",
      "Epoch 38 Completed - Avg Loss: 10.8884, Avg Acc: 0.5014\n",
      "CPU times: total: 5min 3s\n",
      "Wall time: 5min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n오버피팅이 나는 것 같습니다.\\n\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=38,  # 원하는 에폭 수\n",
    "    device=device\n",
    ")\n",
    "\n",
    "'''\n",
    "오버피팅이 나는 것 같습니다.\n",
    "epoch를 60으로 했을때 수렴하는 38로 조정\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07ed3a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n훈련 할 적에 특수 토큰을 넣었더니 출력도 토큰이 같이나오는 현상 때문에\\n금지토큰을 마스킹.\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decoder_inference(model, sentence, tokenizer, device='cuda'):\n",
    "    START_TOKEN = tokenizer.bos_id()\n",
    "    END_TOKEN   = tokenizer.eos_id()\n",
    "    MAX_LENGTH  = 64\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    prefix_text = f\"<user> {sentence} $ <assistant>\"\n",
    "    prefix_ids  = tokenizer.encode(prefix_text)\n",
    "\n",
    "    # 초기 입력: [BOS] + prefix\n",
    "    input_ids = torch.tensor([[START_TOKEN] + prefix_ids], dtype=torch.long, device=device)\n",
    "\n",
    "    # 금지 토큰: 생성 단계에서 막을 목록\n",
    "    forbid_pieces = [\"<user>\", \"<assistant>\", \"<label_0>\", \"<label_1>\", \"<label_2>\", \"$\"]\n",
    "    forbid_ids = [tokenizer.piece_to_id(p) for p in forbid_pieces if tokenizer.piece_to_id(p) >= 0]\n",
    "    # EOS는 허용해야 종료 가능. BOS는 어차피 안 나옴.\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(MAX_LENGTH):\n",
    "            logits = model(input_ids)                  # [B, T, V]\n",
    "            step_logits = logits[:, -1, :].clone()     # [B, V]\n",
    "\n",
    "            # 금지 토큰 마스킹\n",
    "            if forbid_ids:\n",
    "                step_logits[:, forbid_ids] = -1e9\n",
    "\n",
    "            next_id = torch.argmax(step_logits, dim=-1)  # 그리디\n",
    "\n",
    "            if next_id.item() == END_TOKEN:\n",
    "                break\n",
    "\n",
    "            input_ids = torch.cat([input_ids, next_id.unsqueeze(1)], dim=1)\n",
    "\n",
    "    # 프롬프트 뒤의 생성 구간만 반환\n",
    "    prefix_len = 1 + len(prefix_ids)  # [BOS] + prefix\n",
    "    generated = input_ids[:, prefix_len:]\n",
    "    return generated.squeeze(0).tolist()\n",
    "'''\n",
    "훈련 할 적에 특수 토큰을 넣었더니 출력도 토큰이 같이나오는 현상 때문에\n",
    "금지토큰을 마스킹.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "119aba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, sentence, tokenizer, device='cuda'):\n",
    "    gen_ids = decoder_inference(model, sentence, tokenizer, device=device)\n",
    "\n",
    "    # 생성 구간만 디코딩. 특수토큰 제거(혹시 섞였을 대비).\n",
    "    forbids_ids = {\n",
    "        tokenizer.bos_id(), tokenizer.eos_id(), tokenizer.pad_id(),\n",
    "        tokenizer.piece_to_id(\"<user>\"), tokenizer.piece_to_id(\"<assistant>\"),\n",
    "        tokenizer.piece_to_id(\"<label_0>\"), tokenizer.piece_to_id(\"<label_1>\"),\n",
    "        tokenizer.piece_to_id(\"<label_2>\"), tokenizer.piece_to_id(\"$\")\n",
    "    }\n",
    "    clean_ids = [t for t in gen_ids if t not in forbids_ids and t < tokenizer.GetPieceSize()]\n",
    "\n",
    "    predicted_sentence = tokenizer.decode(clean_ids)\n",
    "\n",
    "    print(\"입력 :\", sentence)\n",
    "    print(\"출력 :\", predicted_sentence)\n",
    "    return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ebebd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_to_llm(num, path, model, sp, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    num: 생성할 문장 개수\n",
    "    path: ChatbotData.csv 경로\n",
    "    model: 학습된 Transformer 모델\n",
    "    sp: SentencePiece tokenizer\n",
    "    \"\"\"\n",
    "    path = \"ChatbotData.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    sentences = []\n",
    "\n",
    "    # Q 컬럼에서 랜덤으로 num개 추출\n",
    "    sample_qs = random.sample(df[\"Q\"].tolist(), num)\n",
    "\n",
    "    for sentence in sample_qs:\n",
    "        sentence = str(sentence).strip()\n",
    "        sentence_generation(model, sentence, sp, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f5dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "데이터에서 랜덤 추출\n",
    "감정 토큰을 프리픽스 시켜서 추론하는 것이 맞는것인지?\n",
    "'''\n",
    "\n",
    "real = [\n",
    "\"오늘은 왜 이렇게 피곤하지?\",\n",
    "\"내일 뭐 입을까?\",\n",
    "\"밥은 먹었어?\",\n",
    "\"요즘 너무 바빠서 힘들어.\",\n",
    "\"주말에 뭐 할까 고민돼.\"\n",
    "\"날씨가 진짜 덥다.\",\n",
    "\"커피를 너무 많이 마신 것 같아.\",\n",
    "\"요즘 잠이 잘 안 와.\",\n",
    "\"그냥 아무 생각 없이 쉬고 싶다.\",\n",
    "\"오늘 하루는 평범했어.\",\n",
    "\"이제 정말 끝인 것 같아.\",\n",
    "\"연락이 점점 줄어들고 있어.\",\n",
    "\"나만 힘든 걸까?\",\n",
    "\"그 사람 생각이 자꾸 나.\",\n",
    "\"미련이 남아서 괴롭다.\",\n",
    "\"혼자 있는 게 익숙해지는 게 슬퍼.\",\n",
    "\"마음이 식은 게 느껴져.\",\n",
    "\"내가 뭘 잘못한 걸까.\",\n",
    "\"아직도 그때 일이 떠올라.\",\n",
    "\"사랑이 이렇게 아픈 줄 몰랐어.\",\n",
    "\"오늘 그 사람 웃는 게 너무 예뻤어.\",\n",
    "\"같이 있을 때 제일 행복해.\",\n",
    "\"괜히 생각만 해도 기분이 좋아.\",\n",
    "\"그 사람이랑 통화하면 하루가 즐거워져.\",\n",
    "\"눈만 봐도 마음이 편해.\",\n",
    "\"요즘 매일 설레.\",\n",
    "\"사랑받는다는 느낌이 이런 걸까.\",\n",
    "\"선물 고르면서 괜히 웃음 나왔어.\",\n",
    "\"만나면 시간이 너무 빨리 가.\",\n",
    "\"그냥 그 사람이 좋다.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c89fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "위 함수에서는 데이터에서 추출하였지만 real은 gpt를 통해 데이터에 존재하지않는\n",
    "문장으로 추론.\n",
    "'''\n",
    "\n",
    "def depends_on_real():\n",
    "    for i in real:\n",
    "        sentence_generation(model, i, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44aa04a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘은 왜 이렇게 피곤하지?\n",
      "출력 : 좋은 사람 사람 .\n",
      "입력 : 내일 뭐 입을까?\n",
      "출력 : 좋은 사람 사람 .\n",
      "입력 : 밥은 먹었어?\n",
      "출력 : 좋은 사람 사람 .\n",
      "입력 : 요즘 너무 바빠서 힘들어.\n",
      "출력 : 좋은 사람 사람 .\n",
      "입력 : 주말에 뭐 할까 고민돼.날씨가 진짜 덥다.\n",
      "출력 : 더 많이 많이 많이 많이 많이 많이 많이 많이 많이 .\n",
      "입력 : 커피를 너무 많이 마신 것 같아.\n",
      "출력 : 더 많이 많이 많이 많이 많이 많이 많이 많이 많이 많이 많이 .\n",
      "입력 : 요즘 잠이 잘 안 와.\n",
      "출력 : 더 좋은 사람 .\n",
      "입력 : 그냥 아무 생각 없이 쉬고 싶다.\n",
      "출력 : 좋은 사람 사람 .\n",
      "입력 : 오늘 하루는 평범했어.\n",
      "출력 : 좋은 사람 사람 .\n",
      "입력 : 이제 정말 끝인 것 같아.\n",
      "출력 : 더 좋은 사람 .\n",
      "입력 : 연락이 점점 줄어들고 있어.\n",
      "출력 : 더 좋은 사람 .\n",
      "입력 : 나만 힘든 걸까?\n",
      "출력 : 좋은 사람 .\n",
      "입력 : 그 사람 생각이 자꾸 나.\n",
      "출력 : 좋은 사람 사람 .\n",
      "입력 : 미련이 남아서 괴롭다.\n",
      "출력 : 더 좋은 사람 .\n",
      "입력 : 혼자 있는 게 익숙해지는 게 슬퍼.\n",
      "출력 : 더 좋은 사람 .\n",
      "입력 : 마음이 식은 게 느껴져.\n",
      "출력 : 더 좋은 사람 .\n",
      "입력 : 내가 뭘 잘못한 걸까.\n",
      "출력 : 더 좋은 사람 .\n",
      "입력 : 아직도 그때 일이 떠올라.\n",
      "출력 : 더 좋은 사람 .\n",
      "입력 : 사랑이 이렇게 아픈 줄 몰랐어.\n",
      "출력 : 더 좋은 사람 .\n",
      "입력 : 오늘 그 사람 웃는 게 너무 예뻤어.\n",
      "출력 : 더 더 더 더 좋은 사람 .\n",
      "입력 : 같이 있을 때 제일 행복해.\n",
      "출력 : 좋은 사람 .\n",
      "입력 : 괜히 생각만 해도 기분이 좋아.\n",
      "출력 : 좋은 사람 사람 .\n",
      "입력 : 그 사람이랑 통화하면 하루가 즐거워져.\n",
      "출력 : 좋은 사람 사람 .\n",
      "입력 : 눈만 봐도 마음이 편해.\n",
      "출력 : 더 많이 많이 많이 많이 많이 많이 .\n",
      "입력 : 요즘 매일 설레.\n",
      "출력 : 좋은 사람 .\n",
      "입력 : 사랑받는다는 느낌이 이런 걸까.\n",
      "출력 : 좋은 사람 사람 .\n",
      "입력 : 선물 고르면서 괜히 웃음 나왔어.\n",
      "출력 : 더 많이 많이 많이 많이 많이 많이 많이 많이 .\n",
      "입력 : 만나면 시간이 너무 빨리 가.\n",
      "출력 : 더 많이 많이 많이 많이 많이 많이 많이 .\n",
      "입력 : 그냥 그 사람이 좋다.\n",
      "출력 : 더 좋은 사람 .\n"
     ]
    }
   ],
   "source": [
    "depends_on_real()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jedi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
